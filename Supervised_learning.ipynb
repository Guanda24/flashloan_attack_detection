{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d5f53f-40d0-4480-ae47-0c3d3471df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report, precision_recall_curve, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b265e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "threshold = 34000\n",
    "\n",
    "# Load the datasets\n",
    "attack_label = pd.read_csv('/local/scratch/exported/MP_Defi_txs_TY_23/guanda/attack_label.csv')\n",
    "unlabeled = pd.read_csv('/local/scratch/exported/MP_Defi_txs_TY_23/guanda/unlabeled.csv')\n",
    "\n",
    "# Select features\n",
    "features = ['from_address_profit', 'to_address_profit', 'highest_profit_in_usd',\n",
    "            'highest_price_change_ratio', 'path_length', 'num_swap_events', 'flashloan_in_usd']\n",
    "\n",
    "# Preprocessing\n",
    "unlabeled['flashloan_in_usd'] = pd.to_numeric(unlabeled['flashloan_in_usd'], errors='coerce')\n",
    "normal_label = unlabeled[unlabeled['highest_profit_in_usd'] <= 1000]\n",
    "unlabeled = unlabeled[unlabeled['highest_profit_in_usd'] > 1000].reset_index(drop=True)\n",
    "\n",
    "# Add a new column for labels: 1 for attack and 0 for normal\n",
    "attack_label['label'] = 1  # Attack\n",
    "normal_label['label'] = 0  # Normal\n",
    "\n",
    "# Combine the datasets\n",
    "combined_df = pd.concat([attack_label, normal_label], ignore_index=True)\n",
    "\n",
    "# Convert 'flashloan_in_usd' to numeric, coercing errors to NaN\n",
    "combined_df['flashloan_in_usd'] = pd.to_numeric(combined_df['flashloan_in_usd'], errors='coerce')\n",
    "\n",
    "X = combined_df[features]\n",
    "y = combined_df['label']\n",
    "X_unlabeled = unlabeled[features]\n",
    "\n",
    "# Combine X and X_unlabeled temporarily for imputation and scaling\n",
    "X_combined = np.vstack([X, X_unlabeled])\n",
    "\n",
    "# Handle missing values by imputing with the mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_combined_imputed = imputer.fit_transform(X_combined)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined_imputed)\n",
    "\n",
    "# Separate them back into X and X_unlabeled\n",
    "X_scaled = X_combined_scaled[:len(X), :]\n",
    "X_unlabeled_scaled = X_combined_scaled[len(X):, :]\n",
    "\n",
    "temp = [\n",
    "\"0x3b19e152943f31fe0830b67315ddc89be9a066dc89174256e17bc8c2d35b5af8\",\n",
    "\"0xcb0ad9da33ecabf75df0a24aabf8a4517e4a7c5b1b2f11fee3b6a1ad9299a282\",\n",
    "\"0xcb58fb952914896b35d909136b9f719b71fc8bc60b59853459fc2476d4369c3a\",\n",
    "\"0xf72f1d10fc6923f87279ce6c0aef46e372c6652a696f280b0465a301a92f2e26\",\n",
    "\"0x118b7b7c11f9e9bd630ea84ef267b183b34021b667f4a3061f048207d266437a\",\n",
    "\"0x3503253131644dd9f52802d071de74e456570374d586ddd640159cf6fb9b8ad8\",\n",
    "\"0x35f8d2f572fceaac9288e5d462117850ef2694786992a8c3f6d02612277b0877\",\n",
    "\"0x0fc6d2ca064fc841bc9b1c1fad1fbb97bcea5c9a1b2b66ef837f1227e06519a6\",\n",
    "\"0x958236266991bc3fe3b77feaacea120f172c0708ad01c7a715b255f218f9313c\",\n",
    "\"0x46a03488247425f845e444b9c10b52ba3c14927c687d38287c0faddc7471150a\",\n",
    "\"0x8bb8dc5c7c830bac85fa48acad2505e9300a91c3ff239c9517d0cae33b595090\",\n",
    "\"0xf6022012b73770e7e2177129e648980a82aab555f9ac88b8a9cda3ec44b30779\",\n",
    "\"0xcd314668aaa9bbfebaf1a0bd2b6553d01dd58899c508d4729fa7311dc5d33ad7\"\n",
    "]\n",
    "\n",
    "indices_temp = combined_df[combined_df['tx_hash'].isin(temp)].index\n",
    "\n",
    "X_temp_scaled = X_scaled[indices_temp]\n",
    "y_temp = y.iloc[indices_temp]\n",
    "\n",
    "X_scaled_removed = np.delete(X_scaled, indices_temp, axis=0)\n",
    "y_array = np.array(y) \n",
    "y_removed = np.delete(y_array, indices_temp, axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_removed, y_removed, test_size=0.2, random_state=42, stratify=y_removed)\n",
    "\n",
    "X_train = np.vstack([X_train, X_temp_scaled])\n",
    "y_train = np.concatenate([y_train, y_temp])\n",
    "\n",
    "unlabeled_predictions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907af5c",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83543763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 15:24:41,341] A new study created in memory with name: no-name-f3a3f1c4-7095-4c52-9ddf-ffc059c48d01\n",
      "[I 2025-01-30 15:25:06,782] Trial 0 finished with value: 0.9276573743251735 and parameters: {'n_estimators': 24, 'max_depth': 20, 'min_samples_split': 9}. Best is trial 0 with value: 0.9276573743251735.\n",
      "[I 2025-01-30 15:25:19,919] Trial 1 finished with value: 0.0026646951909938834 and parameters: {'n_estimators': 157, 'max_depth': 1, 'min_samples_split': 3}. Best is trial 0 with value: 0.9276573743251735.\n",
      "[I 2025-01-30 15:25:21,913] Trial 2 finished with value: 0.0026646951909938834 and parameters: {'n_estimators': 13, 'max_depth': 1, 'min_samples_split': 8}. Best is trial 0 with value: 0.9276573743251735.\n",
      "[I 2025-01-30 15:25:42,679] Trial 3 finished with value: 0.8598051689758923 and parameters: {'n_estimators': 50, 'max_depth': 11, 'min_samples_split': 2}. Best is trial 0 with value: 0.9276573743251735.\n",
      "[I 2025-01-30 15:26:40,053] Trial 4 finished with value: 0.9298755720686254 and parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 4 with value: 0.9298755720686254.\n",
      "[I 2025-01-30 15:27:51,461] Trial 5 finished with value: 0.8863290802665815 and parameters: {'n_estimators': 156, 'max_depth': 14, 'min_samples_split': 10}. Best is trial 4 with value: 0.9298755720686254.\n",
      "[I 2025-01-30 15:28:31,395] Trial 6 finished with value: 0.8494225498577379 and parameters: {'n_estimators': 111, 'max_depth': 10, 'min_samples_split': 6}. Best is trial 4 with value: 0.9298755720686254.\n",
      "[I 2025-01-30 15:29:16,624] Trial 7 finished with value: 0.8790323402498015 and parameters: {'n_estimators': 101, 'max_depth': 13, 'min_samples_split': 7}. Best is trial 4 with value: 0.9298755720686254.\n",
      "[I 2025-01-30 15:29:35,005] Trial 8 finished with value: 0.6642011167288856 and parameters: {'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2}. Best is trial 4 with value: 0.9298755720686254.\n",
      "[I 2025-01-30 15:29:45,982] Trial 9 finished with value: 0.8759680717099005 and parameters: {'n_estimators': 22, 'max_depth': 13, 'min_samples_split': 6}. Best is trial 4 with value: 0.9298755720686254.\n",
      "[I 2025-01-30 15:31:38,720] Trial 10 finished with value: 0.9314099821827273 and parameters: {'n_estimators': 198, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 10 with value: 0.9314099821827273.\n",
      "[I 2025-01-30 15:33:26,229] Trial 11 finished with value: 0.9279501692537648 and parameters: {'n_estimators': 191, 'max_depth': 19, 'min_samples_split': 4}. Best is trial 10 with value: 0.9314099821827273.\n",
      "[I 2025-01-30 15:34:03,412] Trial 12 finished with value: 0.9169133507924618 and parameters: {'n_estimators': 70, 'max_depth': 17, 'min_samples_split': 5}. Best is trial 10 with value: 0.9314099821827273.\n",
      "[I 2025-01-30 15:35:15,049] Trial 13 finished with value: 0.9166301657171385 and parameters: {'n_estimators': 136, 'max_depth': 17, 'min_samples_split': 7}. Best is trial 10 with value: 0.9314099821827273.\n",
      "[I 2025-01-30 15:36:07,047] Trial 14 finished with value: 0.7450476022667234 and parameters: {'n_estimators': 199, 'max_depth': 7, 'min_samples_split': 5}. Best is trial 10 with value: 0.9314099821827273.\n",
      "[I 2025-01-30 15:36:48,216] Trial 15 finished with value: 0.9165384657704243 and parameters: {'n_estimators': 76, 'max_depth': 17, 'min_samples_split': 8}. Best is trial 10 with value: 0.9314099821827273.\n",
      "[I 2025-01-30 15:38:05,335] Trial 16 finished with value: 0.9315235040037451 and parameters: {'n_estimators': 131, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:39:29,007] Trial 17 finished with value: 0.899800168578408 and parameters: {'n_estimators': 172, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:40:38,003] Trial 18 finished with value: 0.9231105096993248 and parameters: {'n_estimators': 126, 'max_depth': 18, 'min_samples_split': 4}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:41:35,014] Trial 19 finished with value: 0.8414735858865529 and parameters: {'n_estimators': 174, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:42:46,627] Trial 20 finished with value: 0.9097587728673526 and parameters: {'n_estimators': 144, 'max_depth': 16, 'min_samples_split': 3}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:43:39,732] Trial 21 finished with value: 0.9314961356451983 and parameters: {'n_estimators': 84, 'max_depth': 20, 'min_samples_split': 6}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:44:25,754] Trial 22 finished with value: 0.9314035517926438 and parameters: {'n_estimators': 81, 'max_depth': 20, 'min_samples_split': 6}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:44:55,874] Trial 23 finished with value: 0.924686685750439 and parameters: {'n_estimators': 55, 'max_depth': 18, 'min_samples_split': 5}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:46:05,005] Trial 24 finished with value: 0.9260088450550231 and parameters: {'n_estimators': 124, 'max_depth': 19, 'min_samples_split': 6}. Best is trial 16 with value: 0.9315235040037451.\n",
      "[I 2025-01-30 15:46:30,363] Trial 25 finished with value: 0.9316092553685664 and parameters: {'n_estimators': 42, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:47:00,667] Trial 26 finished with value: 0.900265879894296 and parameters: {'n_estimators': 62, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:47:24,132] Trial 27 finished with value: 0.9220824202268171 and parameters: {'n_estimators': 41, 'max_depth': 18, 'min_samples_split': 4}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:48:08,249] Trial 28 finished with value: 0.9106654084741919 and parameters: {'n_estimators': 86, 'max_depth': 16, 'min_samples_split': 3}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:48:19,834] Trial 29 finished with value: 0.7220269976501327 and parameters: {'n_estimators': 36, 'max_depth': 6, 'min_samples_split': 8}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:48:37,928] Trial 30 finished with value: 0.9281202678316373 and parameters: {'n_estimators': 31, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:49:43,230] Trial 31 finished with value: 0.9314992300305599 and parameters: {'n_estimators': 115, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:50:45,392] Trial 32 finished with value: 0.9279187474590289 and parameters: {'n_estimators': 114, 'max_depth': 19, 'min_samples_split': 4}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:51:35,497] Trial 33 finished with value: 0.9227428672255316 and parameters: {'n_estimators': 92, 'max_depth': 18, 'min_samples_split': 6}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:51:42,925] Trial 34 finished with value: 0.9256200361072311 and parameters: {'n_estimators': 10, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:52:49,832] Trial 35 finished with value: 0.92771863529223 and parameters: {'n_estimators': 119, 'max_depth': 19, 'min_samples_split': 4}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:53:50,401] Trial 36 finished with value: 0.8674310908275208 and parameters: {'n_estimators': 147, 'max_depth': 12, 'min_samples_split': 6}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:54:58,737] Trial 37 finished with value: 0.8991598829187992 and parameters: {'n_estimators': 132, 'max_depth': 15, 'min_samples_split': 9}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:55:33,035] Trial 38 finished with value: 0.9094920921570069 and parameters: {'n_estimators': 66, 'max_depth': 16, 'min_samples_split': 2}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:55:45,400] Trial 39 finished with value: 0.5810150586674657 and parameters: {'n_estimators': 91, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:56:45,434] Trial 40 finished with value: 0.9295563690935937 and parameters: {'n_estimators': 107, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 25 with value: 0.9316092553685664.\n",
      "[I 2025-01-30 15:58:19,376] Trial 41 finished with value: 0.9316237167543768 and parameters: {'n_estimators': 167, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 41 with value: 0.9316237167543768.\n",
      "[I 2025-01-30 15:59:51,621] Trial 42 finished with value: 0.9265647161056194 and parameters: {'n_estimators': 169, 'max_depth': 19, 'min_samples_split': 6}. Best is trial 41 with value: 0.9316237167543768.\n",
      "[I 2025-01-30 16:01:14,606] Trial 43 finished with value: 0.9239598323722568 and parameters: {'n_estimators': 148, 'max_depth': 18, 'min_samples_split': 3}. Best is trial 41 with value: 0.9316237167543768.\n",
      "[I 2025-01-30 16:01:43,001] Trial 44 finished with value: 0.9303728594157098 and parameters: {'n_estimators': 47, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 41 with value: 0.9316237167543768.\n",
      "[I 2025-01-30 16:02:55,530] Trial 45 finished with value: 0.9163206313788347 and parameters: {'n_estimators': 137, 'max_depth': 17, 'min_samples_split': 4}. Best is trial 41 with value: 0.9316237167543768.\n",
      "[I 2025-01-30 16:04:22,721] Trial 46 finished with value: 0.9281461926223044 and parameters: {'n_estimators': 160, 'max_depth': 19, 'min_samples_split': 5}. Best is trial 41 with value: 0.9316237167543768.\n",
      "[I 2025-01-30 16:05:18,133] Trial 47 finished with value: 0.9301648378382256 and parameters: {'n_estimators': 96, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 41 with value: 0.9316237167543768.\n",
      "[I 2025-01-30 16:05:37,419] Trial 48 finished with value: 0.9214905866812145 and parameters: {'n_estimators': 25, 'max_depth': 18, 'min_samples_split': 6}. Best is trial 41 with value: 0.9316237167543768.\n",
      "[I 2025-01-30 16:07:01,170] Trial 49 finished with value: 0.8884889815800479 and parameters: {'n_estimators': 184, 'max_depth': 14, 'min_samples_split': 4}. Best is trial 41 with value: 0.9316237167543768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved new Random Forest model.\n",
      "Number of 0s (normal): 160810\n",
      "Number of 1s (attack): 69946\n",
      "                      Feature  Importance\n",
      "6            flashloan_in_usd    0.298553\n",
      "1           to_address_profit    0.272717\n",
      "0         from_address_profit    0.208211\n",
      "2       highest_profit_in_usd    0.092140\n",
      "4                 path_length    0.089531\n",
      "5             num_swap_events    0.030892\n",
      "3  highest_price_change_ratio    0.007955\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def rf_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                   min_samples_split=min_samples_split, random_state=42)\n",
    "    \n",
    "    # Use StratifiedKFold for stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=skf, n_jobs=-1, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Check if the model already exists\n",
    "if os.path.exists(f'Models/{threshold}/random_forest_model_{threshold}.pkl'):\n",
    "    # Load the existing model\n",
    "    best_model = joblib.load(f'Models/{threshold}/random_forest_model_{threshold}.pkl')\n",
    "    print(\"Loaded existing Random Forest model.\")\n",
    "    best_params = best_model.get_params()\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "else: \n",
    "    # Optimize with Optuna\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(rf_objective, n_trials=50)\n",
    "\n",
    "    # Best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    # Save the model\n",
    "    joblib.dump(best_model, f'Models/{threshold}/random_forest_model_{threshold}.pkl')\n",
    "    print(\"Trained and saved new Random Forest model.\")\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate confusion matrix and AUC-ROC score\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame to store Precision-Recall data\n",
    "pr_data_df = pd.DataFrame({\n",
    "    'Recall': recall,\n",
    "    'Precision': precision\n",
    "})\n",
    "\n",
    "# Save the Precision-Recall data to a CSV file\n",
    "pr_data_df.to_csv('Models/random_forest_precision_recall_data.csv', index=False)\n",
    "\n",
    "# Prepare confusion matrix data\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_list = [\n",
    "    {'Metric': 'True Negatives', 'Value': tn},\n",
    "    {'Metric': 'False Positives', 'Value': fp},\n",
    "    {'Metric': 'False Negatives', 'Value': fn},\n",
    "    {'Metric': 'True Positives', 'Value': tp},\n",
    "    {'Metric': 'AUC-ROC', 'Value': auc_roc}\n",
    "]\n",
    "\n",
    "# Add classification report data to the metrics DataFrame\n",
    "for label, metrics in class_report.items():\n",
    "    if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        metrics_list.append({'Metric': f'Precision ({label})', 'Value': metrics['precision']})\n",
    "        metrics_list.append({'Metric': f'Recall ({label})', 'Value': metrics['recall']})\n",
    "        metrics_list.append({'Metric': f'F1-Score ({label})', 'Value': metrics['f1-score']})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv('Models/random_forest_metrics.csv', index=False)\n",
    "\n",
    "# Calculate ROC curve data\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame for ROC curve data\n",
    "roc_data_df = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr,\n",
    "    'Thresholds': thresholds\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Save ROC curve data to CSV\n",
    "roc_data_df.to_csv('Models/random_forest_roc_data.csv', index=False)\n",
    "\n",
    "# Predict the labels for the unlabeled dataset\n",
    "rf_y_unlabeled_pred = best_model.predict(X_unlabeled_scaled)\n",
    "\n",
    "# Count the number of 0s and 1s in the predictions\n",
    "num_zeros = np.sum(rf_y_unlabeled_pred == 0)\n",
    "num_ones = np.sum(rf_y_unlabeled_pred == 1)\n",
    "\n",
    "print(f\"Number of 0s (normal): {num_zeros}\")\n",
    "print(f\"Number of 1s (attack): {num_ones}\")\n",
    "\n",
    "unlabeled['prediction'] = rf_y_unlabeled_pred\n",
    "platform_prediction_counts = unlabeled.groupby(['platform', 'prediction']).size().unstack(fill_value=0)\n",
    "platform_prediction_counts.to_csv('Models/random_forest_unlabeled_platform_prediction_counts.csv')\n",
    "\n",
    "unlabeled_predictions['Random_Forest'] = rf_y_unlabeled_pred\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8e6c5",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8a9f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 16:08:47,828] A new study created in memory with name: no-name-0c72b275-3a7a-4b15-840c-efca0f4bb1fa\n",
      "[I 2025-01-30 16:09:02,000] Trial 0 finished with value: 0.8287656597742922 and parameters: {'n_neighbors': 47, 'weights': 'distance'}. Best is trial 0 with value: 0.8287656597742922.\n",
      "[I 2025-01-30 16:09:10,728] Trial 1 finished with value: 0.8409137067250654 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 1 with value: 0.8409137067250654.\n",
      "[I 2025-01-30 16:09:19,859] Trial 2 finished with value: 0.8446430270465457 and parameters: {'n_neighbors': 6, 'weights': 'uniform'}. Best is trial 2 with value: 0.8446430270465457.\n",
      "[I 2025-01-30 16:09:31,633] Trial 3 finished with value: 0.833627417039493 and parameters: {'n_neighbors': 37, 'weights': 'distance'}. Best is trial 2 with value: 0.8446430270465457.\n",
      "[I 2025-01-30 16:09:43,051] Trial 4 finished with value: 0.8114221707038449 and parameters: {'n_neighbors': 23, 'weights': 'uniform'}. Best is trial 2 with value: 0.8446430270465457.\n",
      "[I 2025-01-30 16:09:50,725] Trial 5 finished with value: 0.856108804917949 and parameters: {'n_neighbors': 4, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:09:59,819] Trial 6 finished with value: 0.8551275307968191 and parameters: {'n_neighbors': 9, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:10:07,730] Trial 7 finished with value: 0.856108804917949 and parameters: {'n_neighbors': 4, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:10:21,056] Trial 8 finished with value: 0.7813531905554898 and parameters: {'n_neighbors': 46, 'weights': 'uniform'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:10:34,132] Trial 9 finished with value: 0.7804977029064432 and parameters: {'n_neighbors': 49, 'weights': 'uniform'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:10:44,449] Trial 10 finished with value: 0.8453226077241215 and parameters: {'n_neighbors': 22, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:10:51,474] Trial 11 finished with value: 0.8425959351179628 and parameters: {'n_neighbors': 1, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:11:01,452] Trial 12 finished with value: 0.8498739968497387 and parameters: {'n_neighbors': 16, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:11:12,108] Trial 13 finished with value: 0.8366742795739388 and parameters: {'n_neighbors': 33, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:11:21,539] Trial 14 finished with value: 0.8498739968497387 and parameters: {'n_neighbors': 16, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:11:28,066] Trial 15 finished with value: 0.8425959351179628 and parameters: {'n_neighbors': 1, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:11:37,200] Trial 16 finished with value: 0.8510918162473192 and parameters: {'n_neighbors': 15, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:11:48,221] Trial 17 finished with value: 0.8394980155629135 and parameters: {'n_neighbors': 30, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:11:57,455] Trial 18 finished with value: 0.8538503473508111 and parameters: {'n_neighbors': 12, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:12:04,343] Trial 19 finished with value: 0.8518223680673452 and parameters: {'n_neighbors': 3, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:12:13,952] Trial 20 finished with value: 0.8488109477168425 and parameters: {'n_neighbors': 18, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:12:22,185] Trial 21 finished with value: 0.855764161488674 and parameters: {'n_neighbors': 8, 'weights': 'distance'}. Best is trial 5 with value: 0.856108804917949.\n",
      "[I 2025-01-30 16:12:29,972] Trial 22 finished with value: 0.8573217533361481 and parameters: {'n_neighbors': 6, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:12:37,949] Trial 23 finished with value: 0.8557983207407187 and parameters: {'n_neighbors': 5, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:12:47,583] Trial 24 finished with value: 0.8538503473508111 and parameters: {'n_neighbors': 12, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:12:56,323] Trial 25 finished with value: 0.853887259747131 and parameters: {'n_neighbors': 11, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:13:04,393] Trial 26 finished with value: 0.8520823001857114 and parameters: {'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:13:13,922] Trial 27 finished with value: 0.8473777568155366 and parameters: {'n_neighbors': 19, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:13:24,786] Trial 28 finished with value: 0.8409810409099467 and parameters: {'n_neighbors': 27, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:13:36,287] Trial 29 finished with value: 0.8315706694538978 and parameters: {'n_neighbors': 40, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:13:43,042] Trial 30 finished with value: 0.8425959351179628 and parameters: {'n_neighbors': 1, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:13:50,680] Trial 31 finished with value: 0.8557983207407187 and parameters: {'n_neighbors': 5, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:13:58,836] Trial 32 finished with value: 0.8568858254035276 and parameters: {'n_neighbors': 7, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:14:07,128] Trial 33 finished with value: 0.8551275307968191 and parameters: {'n_neighbors': 9, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:14:15,971] Trial 34 finished with value: 0.8468691376116194 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:14:24,529] Trial 35 finished with value: 0.8525030348220692 and parameters: {'n_neighbors': 13, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:14:32,260] Trial 36 finished with value: 0.8550962540823914 and parameters: {'n_neighbors': 3, 'weights': 'uniform'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:14:40,828] Trial 37 finished with value: 0.854372179235836 and parameters: {'n_neighbors': 10, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:14:48,994] Trial 38 finished with value: 0.8568858254035276 and parameters: {'n_neighbors': 7, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:14:57,427] Trial 39 finished with value: 0.8468691376116194 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:15:07,438] Trial 40 finished with value: 0.8453226077241215 and parameters: {'n_neighbors': 22, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:15:14,862] Trial 41 finished with value: 0.856108804917949 and parameters: {'n_neighbors': 4, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:15:23,133] Trial 42 finished with value: 0.855764161488674 and parameters: {'n_neighbors': 8, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:15:31,759] Trial 43 finished with value: 0.8515626529626541 and parameters: {'n_neighbors': 14, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:15:39,121] Trial 44 finished with value: 0.8518223680673452 and parameters: {'n_neighbors': 3, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:15:47,036] Trial 45 finished with value: 0.8573217533361481 and parameters: {'n_neighbors': 6, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:15:55,417] Trial 46 finished with value: 0.854372179235836 and parameters: {'n_neighbors': 10, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:16:06,067] Trial 47 finished with value: 0.8123226784568665 and parameters: {'n_neighbors': 20, 'weights': 'uniform'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:16:14,285] Trial 48 finished with value: 0.8573217533361481 and parameters: {'n_neighbors': 6, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n",
      "[I 2025-01-30 16:16:22,435] Trial 49 finished with value: 0.8568858254035276 and parameters: {'n_neighbors': 7, 'weights': 'distance'}. Best is trial 22 with value: 0.8573217533361481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved new K-Nearest Neighbors model.\n",
      "Number of 0s (normal): 195024\n",
      "Number of 1s (attack): 35732\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 50)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "    \n",
    "    # Use StratifiedKFold for stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=skf, n_jobs=-1, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Check if the model already exists\n",
    "if os.path.exists(f'Models/{threshold}/knn_model_{threshold}.pkl'):\n",
    "    # Load the existing model\n",
    "    best_model = joblib.load(f'Models/{threshold}/knn_model_{threshold}.pkl')\n",
    "    print(\"Loaded existing K-Nearest Neighbors model.\")\n",
    "    best_params = best_model.get_params()\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "else: \n",
    "    # Optimize with Optuna\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(knn_objective, n_trials=50)\n",
    "\n",
    "    # Best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = KNeighborsClassifier(**best_params)\n",
    "    # Save the model\n",
    "    joblib.dump(best_model, f'Models/{threshold}/knn_model_{threshold}.pkl')\n",
    "    print(\"Trained and saved new K-Nearest Neighbors model.\")\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate confusion matrix and AUC-ROC score\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame to store Precision-Recall data\n",
    "pr_data_df = pd.DataFrame({\n",
    "    'Recall': recall,\n",
    "    'Precision': precision\n",
    "})\n",
    "\n",
    "# Save the Precision-Recall data to a CSV file\n",
    "pr_data_df.to_csv('Models/knn_precision_recall_data.csv', index=False)\n",
    "\n",
    "# Prepare confusion matrix data\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_list = [\n",
    "    {'Metric': 'True Negatives', 'Value': tn},\n",
    "    {'Metric': 'False Positives', 'Value': fp},\n",
    "    {'Metric': 'False Negatives', 'Value': fn},\n",
    "    {'Metric': 'True Positives', 'Value': tp},\n",
    "    {'Metric': 'AUC-ROC', 'Value': auc_roc}\n",
    "]\n",
    "\n",
    "# Add classification report data to the metrics DataFrame\n",
    "for label, metrics in class_report.items():\n",
    "    if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        metrics_list.append({'Metric': f'Precision ({label})', 'Value': metrics['precision']})\n",
    "        metrics_list.append({'Metric': f'Recall ({label})', 'Value': metrics['recall']})\n",
    "        metrics_list.append({'Metric': f'F1-Score ({label})', 'Value': metrics['f1-score']})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv('Models/knn_metrics.csv', index=False)\n",
    "\n",
    "# Calculate ROC curve data\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame for ROC curve data\n",
    "roc_data_df = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr,\n",
    "    'Thresholds': thresholds\n",
    "})\n",
    "\n",
    "# Save ROC curve data to CSV\n",
    "roc_data_df.to_csv('Models/knn_roc_data.csv', index=False)\n",
    "\n",
    "# Predict the labels for the unlabeled dataset\n",
    "knn_y_unlabeled_pred = best_model.predict(X_unlabeled_scaled)\n",
    "\n",
    "# Count the number of 0s and 1s in the predictions\n",
    "num_zeros = np.sum(knn_y_unlabeled_pred == 0)\n",
    "num_ones = np.sum(knn_y_unlabeled_pred == 1)\n",
    "\n",
    "print(f\"Number of 0s (normal): {num_zeros}\")\n",
    "print(f\"Number of 1s (attack): {num_ones}\")\n",
    "\n",
    "unlabeled['prediction'] = knn_y_unlabeled_pred\n",
    "platform_prediction_counts = unlabeled.groupby(['platform', 'prediction']).size().unstack(fill_value=0)\n",
    "platform_prediction_counts.to_csv('Models/knn_unlabeled_platform_prediction_counts.csv')\n",
    "\n",
    "unlabeled_predictions['KNN'] = knn_y_unlabeled_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320a541",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b96102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 16:17:26,700] A new study created in memory with name: no-name-3bb93014-5eb9-4c96-914e-27872dfa8ac1\n",
      "[I 2025-01-30 16:17:29,834] Trial 0 finished with value: 0.9160775088001021 and parameters: {'max_depth': 19, 'min_samples_split': 6}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:32,579] Trial 1 finished with value: 0.8993064231614241 and parameters: {'max_depth': 15, 'min_samples_split': 2}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:35,180] Trial 2 finished with value: 0.8986284026167322 and parameters: {'max_depth': 15, 'min_samples_split': 6}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:37,692] Trial 3 finished with value: 0.8877140553048084 and parameters: {'max_depth': 14, 'min_samples_split': 9}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:39,713] Trial 4 finished with value: 0.8547622686134483 and parameters: {'max_depth': 11, 'min_samples_split': 7}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:42,074] Trial 5 finished with value: 0.8782240418185641 and parameters: {'max_depth': 13, 'min_samples_split': 3}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:44,949] Trial 6 finished with value: 0.9095920665683167 and parameters: {'max_depth': 17, 'min_samples_split': 7}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:46,661] Trial 7 finished with value: 0.8239275908329816 and parameters: {'max_depth': 9, 'min_samples_split': 8}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:49,284] Trial 8 finished with value: 0.8987705479204194 and parameters: {'max_depth': 15, 'min_samples_split': 7}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:50,008] Trial 9 finished with value: 0.39380032123027114 and parameters: {'max_depth': 2, 'min_samples_split': 5}. Best is trial 0 with value: 0.9160775088001021.\n",
      "[I 2025-01-30 16:17:53,238] Trial 10 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 10 with value: 0.9161227742890888.\n",
      "[I 2025-01-30 16:17:56,518] Trial 11 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 10 with value: 0.9161227742890888.\n",
      "[I 2025-01-30 16:17:59,776] Trial 12 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 10 with value: 0.9161227742890888.\n",
      "[I 2025-01-30 16:18:01,382] Trial 13 finished with value: 0.8052607129403603 and parameters: {'max_depth': 8, 'min_samples_split': 10}. Best is trial 10 with value: 0.9161227742890888.\n",
      "[I 2025-01-30 16:18:04,670] Trial 14 finished with value: 0.9166354168841402 and parameters: {'max_depth': 20, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:07,663] Trial 15 finished with value: 0.9122081153829136 and parameters: {'max_depth': 18, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:08,807] Trial 16 finished with value: 0.6879354162933204 and parameters: {'max_depth': 5, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:11,759] Trial 17 finished with value: 0.9103257360198065 and parameters: {'max_depth': 17, 'min_samples_split': 4}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:13,976] Trial 18 finished with value: 0.8672333477695039 and parameters: {'max_depth': 12, 'min_samples_split': 8}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:16,905] Trial 19 finished with value: 0.9086610649463036 and parameters: {'max_depth': 17, 'min_samples_split': 8}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:18,233] Trial 20 finished with value: 0.7627782761946235 and parameters: {'max_depth': 6, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:21,479] Trial 21 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:24,738] Trial 22 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:27,792] Trial 23 finished with value: 0.9117964378247148 and parameters: {'max_depth': 18, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:30,928] Trial 24 finished with value: 0.9122081153829136 and parameters: {'max_depth': 18, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:33,702] Trial 25 finished with value: 0.9044473252118822 and parameters: {'max_depth': 16, 'min_samples_split': 8}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:37,000] Trial 26 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:37,590] Trial 27 finished with value: 0.0 and parameters: {'max_depth': 1, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:40,731] Trial 28 finished with value: 0.9147592032335201 and parameters: {'max_depth': 19, 'min_samples_split': 8}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:43,820] Trial 29 finished with value: 0.9160775088001021 and parameters: {'max_depth': 19, 'min_samples_split': 6}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:46,597] Trial 30 finished with value: 0.9056360613801491 and parameters: {'max_depth': 16, 'min_samples_split': 5}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:49,861] Trial 31 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:53,007] Trial 32 finished with value: 0.9149904405336006 and parameters: {'max_depth': 19, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:56,102] Trial 33 finished with value: 0.9122081153829136 and parameters: {'max_depth': 18, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:18:59,401] Trial 34 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:01,959] Trial 35 finished with value: 0.8888087686224061 and parameters: {'max_depth': 14, 'min_samples_split': 2}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:04,744] Trial 36 finished with value: 0.9044016038655458 and parameters: {'max_depth': 16, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:07,213] Trial 37 finished with value: 0.8872951662071855 and parameters: {'max_depth': 14, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:10,330] Trial 38 finished with value: 0.9156493560557282 and parameters: {'max_depth': 19, 'min_samples_split': 7}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:12,254] Trial 39 finished with value: 0.8370002856604639 and parameters: {'max_depth': 10, 'min_samples_split': 8}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:15,180] Trial 40 finished with value: 0.9095920665683167 and parameters: {'max_depth': 17, 'min_samples_split': 7}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:18,486] Trial 41 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:21,695] Trial 42 finished with value: 0.9161227742890888 and parameters: {'max_depth': 20, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:24,711] Trial 43 finished with value: 0.9122081153829136 and parameters: {'max_depth': 18, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:27,898] Trial 44 finished with value: 0.9150334541869594 and parameters: {'max_depth': 19, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:30,813] Trial 45 finished with value: 0.9083629111175956 and parameters: {'max_depth': 17, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:33,434] Trial 46 finished with value: 0.8972875404502256 and parameters: {'max_depth': 15, 'min_samples_split': 10}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:36,562] Trial 47 finished with value: 0.9150334541869594 and parameters: {'max_depth': 19, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:37,586] Trial 48 finished with value: 0.6571943274046105 and parameters: {'max_depth': 4, 'min_samples_split': 9}. Best is trial 14 with value: 0.9166354168841402.\n",
      "[I 2025-01-30 16:19:40,592] Trial 49 finished with value: 0.9121597812274205 and parameters: {'max_depth': 18, 'min_samples_split': 8}. Best is trial 14 with value: 0.9166354168841402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved new Decision Tree model.\n",
      "Number of 0s (normal): 156813\n",
      "Number of 1s (attack): 73943\n",
      "                      Feature  Importance\n",
      "6            flashloan_in_usd    0.388594\n",
      "1           to_address_profit    0.298802\n",
      "2       highest_profit_in_usd    0.115471\n",
      "4                 path_length    0.092235\n",
      "0         from_address_profit    0.078233\n",
      "5             num_swap_events    0.023285\n",
      "3  highest_price_change_ratio    0.003380\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def dt_objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "    \n",
    "    # Use StratifiedKFold for stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=skf, n_jobs=-1, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Check if the model already exists\n",
    "if os.path.exists(f'Models/{threshold}/decision_tree_model_{threshold}.pkl'):\n",
    "    # Load the existing model\n",
    "    best_model = joblib.load(f'Models/{threshold}/decision_tree_model_{threshold}.pkl')\n",
    "    print(\"Loaded existing Decision Tree model.\")\n",
    "    best_params = best_model.get_params()\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "else: \n",
    "    # Optimize with Optuna\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(dt_objective, n_trials=50)\n",
    "\n",
    "    # Best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "    # Save the model\n",
    "    joblib.dump(best_model, f'Models/{threshold}/decision_tree_model_{threshold}.pkl')\n",
    "    print(\"Trained and saved new Decision Tree model.\")\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate confusion matrix and AUC-ROC score\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame to store Precision-Recall data\n",
    "pr_data_df = pd.DataFrame({\n",
    "    'Recall': recall,\n",
    "    'Precision': precision\n",
    "})\n",
    "\n",
    "# Save the Precision-Recall data to a CSV file\n",
    "pr_data_df.to_csv('Models/decision_tree_precision_recall_data.csv', index=False)\n",
    "\n",
    "# Prepare confusion matrix data\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_list = [\n",
    "    {'Metric': 'True Negatives', 'Value': tn},\n",
    "    {'Metric': 'False Positives', 'Value': fp},\n",
    "    {'Metric': 'False Negatives', 'Value': fn},\n",
    "    {'Metric': 'True Positives', 'Value': tp},\n",
    "    {'Metric': 'AUC-ROC', 'Value': auc_roc}\n",
    "]\n",
    "\n",
    "# Add classification report data to the metrics DataFrame\n",
    "for label, metrics in class_report.items():\n",
    "    if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        metrics_list.append({'Metric': f'Precision ({label})', 'Value': metrics['precision']})\n",
    "        metrics_list.append({'Metric': f'Recall ({label})', 'Value': metrics['recall']})\n",
    "        metrics_list.append({'Metric': f'F1-Score ({label})', 'Value': metrics['f1-score']})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv('Models/decision_tree_metrics.csv', index=False)\n",
    "\n",
    "# Calculate ROC curve data\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame for ROC curve data\n",
    "roc_data_df = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr,\n",
    "    'Thresholds': thresholds\n",
    "})\n",
    "\n",
    "# Save ROC curve data to CSV\n",
    "roc_data_df.to_csv('Models/decision_tree_roc_data.csv', index=False)\n",
    "\n",
    "# Predict the labels for the unlabeled dataset\n",
    "dt_y_unlabeled_pred = best_model.predict(X_unlabeled_scaled)\n",
    "\n",
    "# Count the number of 0s and 1s in the predictions\n",
    "num_zeros = np.sum(dt_y_unlabeled_pred == 0)\n",
    "num_ones = np.sum(dt_y_unlabeled_pred == 1)\n",
    "\n",
    "print(f\"Number of 0s (normal): {num_zeros}\")\n",
    "print(f\"Number of 1s (attack): {num_ones}\")\n",
    "\n",
    "unlabeled['prediction'] = dt_y_unlabeled_pred\n",
    "platform_prediction_counts = unlabeled.groupby(['platform', 'prediction']).size().unstack(fill_value=0)\n",
    "platform_prediction_counts.to_csv('Models/decision_tree_unlabeled_platform_prediction_counts.csv')\n",
    "\n",
    "unlabeled_predictions['Decision_Tree'] = dt_y_unlabeled_pred\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbdad9c",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec17a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 16:19:43,948] A new study created in memory with name: no-name-f5b91147-eadb-41b2-9193-9426eee318d3\n",
      "[I 2025-01-30 16:22:33,249] Trial 0 finished with value: 0.9030958631883393 and parameters: {'n_estimators': 153, 'max_depth': 7}. Best is trial 0 with value: 0.9030958631883393.\n",
      "[I 2025-01-30 16:24:16,607] Trial 1 finished with value: 0.9045524783945753 and parameters: {'n_estimators': 72, 'max_depth': 9}. Best is trial 1 with value: 0.9045524783945753.\n",
      "[I 2025-01-30 16:24:46,772] Trial 2 finished with value: 0.8739906562102935 and parameters: {'n_estimators': 20, 'max_depth': 9}. Best is trial 1 with value: 0.9045524783945753.\n",
      "[I 2025-01-30 16:26:27,383] Trial 3 finished with value: 0.8495102792918946 and parameters: {'n_estimators': 194, 'max_depth': 3}. Best is trial 1 with value: 0.9045524783945753.\n",
      "[I 2025-01-30 16:29:37,342] Trial 4 finished with value: 0.9049423680413599 and parameters: {'n_estimators': 173, 'max_depth': 7}. Best is trial 4 with value: 0.9049423680413599.\n",
      "[I 2025-01-30 16:31:29,925] Trial 5 finished with value: 0.9206143832668412 and parameters: {'n_estimators': 49, 'max_depth': 14}. Best is trial 5 with value: 0.9206143832668412.\n",
      "[I 2025-01-30 16:33:21,647] Trial 6 finished with value: 0.934825964522753 and parameters: {'n_estimators': 33, 'max_depth': 19}. Best is trial 6 with value: 0.934825964522753.\n",
      "[I 2025-01-30 16:34:46,874] Trial 7 finished with value: 0.8905685427905354 and parameters: {'n_estimators': 76, 'max_depth': 7}. Best is trial 6 with value: 0.934825964522753.\n",
      "[I 2025-01-30 16:37:16,800] Trial 8 finished with value: 0.8918436867383521 and parameters: {'n_estimators': 157, 'max_depth': 6}. Best is trial 6 with value: 0.934825964522753.\n",
      "[I 2025-01-30 16:41:15,942] Trial 9 finished with value: 0.9361773667822396 and parameters: {'n_estimators': 85, 'max_depth': 16}. Best is trial 9 with value: 0.9361773667822396.\n",
      "[I 2025-01-30 16:46:51,204] Trial 10 finished with value: 0.9400580466385199 and parameters: {'n_estimators': 119, 'max_depth': 16}. Best is trial 10 with value: 0.9400580466385199.\n",
      "[I 2025-01-30 16:51:42,761] Trial 11 finished with value: 0.9384054382262421 and parameters: {'n_estimators': 110, 'max_depth': 15}. Best is trial 10 with value: 0.9400580466385199.\n",
      "[I 2025-01-30 16:56:04,219] Trial 12 finished with value: 0.9282831986579885 and parameters: {'n_estimators': 122, 'max_depth': 13}. Best is trial 10 with value: 0.9400580466385199.\n",
      "[I 2025-01-30 17:04:13,891] Trial 13 finished with value: 0.9490085584533882 and parameters: {'n_estimators': 118, 'max_depth': 20}. Best is trial 13 with value: 0.9490085584533882.\n",
      "[I 2025-01-30 17:13:05,947] Trial 14 finished with value: 0.9498641882706444 and parameters: {'n_estimators': 131, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 17:22:21,957] Trial 15 finished with value: 0.9497013396802101 and parameters: {'n_estimators': 136, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 17:31:01,406] Trial 16 finished with value: 0.9462835564527179 and parameters: {'n_estimators': 145, 'max_depth': 18}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 17:35:46,598] Trial 17 finished with value: 0.9266863583413961 and parameters: {'n_estimators': 142, 'max_depth': 12}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 17:46:51,993] Trial 18 finished with value: 0.9462852469651117 and parameters: {'n_estimators': 200, 'max_depth': 18}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 17:52:43,112] Trial 19 finished with value: 0.9476800187429877 and parameters: {'n_estimators': 88, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 17:53:17,801] Trial 20 finished with value: 0.6905163576361817 and parameters: {'n_estimators': 135, 'max_depth': 1}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 17:59:37,332] Trial 21 finished with value: 0.9488036296392126 and parameters: {'n_estimators': 97, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 18:08:38,508] Trial 22 finished with value: 0.9441823994429523 and parameters: {'n_estimators': 172, 'max_depth': 17}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 18:17:11,728] Trial 23 finished with value: 0.9495155659025303 and parameters: {'n_estimators': 126, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 18:24:58,620] Trial 24 finished with value: 0.9467726994745123 and parameters: {'n_estimators': 133, 'max_depth': 18}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 18:32:55,262] Trial 25 finished with value: 0.9434960038370098 and parameters: {'n_estimators': 164, 'max_depth': 16}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 18:40:09,641] Trial 26 finished with value: 0.9486072251072993 and parameters: {'n_estimators': 105, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 18:50:46,167] Trial 27 finished with value: 0.9463380423653185 and parameters: {'n_estimators': 185, 'max_depth': 18}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 18:54:50,328] Trial 28 finished with value: 0.9214406192546886 and parameters: {'n_estimators': 129, 'max_depth': 11}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:00:42,877] Trial 29 finished with value: 0.9345980019859222 and parameters: {'n_estimators': 151, 'max_depth': 14}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:04:03,293] Trial 30 finished with value: 0.937786116542066 and parameters: {'n_estimators': 66, 'max_depth': 17}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:11:25,944] Trial 31 finished with value: 0.948857795986193 and parameters: {'n_estimators': 110, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:19:10,534] Trial 32 finished with value: 0.9479874485958284 and parameters: {'n_estimators': 121, 'max_depth': 19}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:25:28,843] Trial 33 finished with value: 0.9474081882248923 and parameters: {'n_estimators': 101, 'max_depth': 19}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:33:04,325] Trial 34 finished with value: 0.944290190509075 and parameters: {'n_estimators': 142, 'max_depth': 17}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:41:10,031] Trial 35 finished with value: 0.9488415913133071 and parameters: {'n_estimators': 117, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:51:14,782] Trial 36 finished with value: 0.948012680719908 and parameters: {'n_estimators': 164, 'max_depth': 19}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 19:57:11,346] Trial 37 finished with value: 0.9403268695028573 and parameters: {'n_estimators': 133, 'max_depth': 15}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 20:02:48,943] Trial 38 finished with value: 0.9471061472084576 and parameters: {'n_estimators': 91, 'max_depth': 19}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 20:06:17,787] Trial 39 finished with value: 0.9119774446228656 and parameters: {'n_estimators': 156, 'max_depth': 8}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 20:11:14,555] Trial 40 finished with value: 0.9228067658959904 and parameters: {'n_estimators': 186, 'max_depth': 10}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 20:19:02,024] Trial 41 finished with value: 0.9487787538133006 and parameters: {'n_estimators': 115, 'max_depth': 20}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 20:20:21,626] Trial 42 finished with value: 0.8585706219442267 and parameters: {'n_estimators': 109, 'max_depth': 4}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 20:24:47,936] Trial 43 finished with value: 0.9453328965292414 and parameters: {'n_estimators': 76, 'max_depth': 19}. Best is trial 14 with value: 0.9498641882706444.\n",
      "[I 2025-01-30 20:33:23,596] Trial 44 finished with value: 0.9501425548916161 and parameters: {'n_estimators': 128, 'max_depth': 20}. Best is trial 44 with value: 0.9501425548916161.\n",
      "[I 2025-01-30 20:41:14,247] Trial 45 finished with value: 0.9450336308507943 and parameters: {'n_estimators': 148, 'max_depth': 17}. Best is trial 44 with value: 0.9501425548916161.\n",
      "[I 2025-01-30 20:48:35,064] Trial 46 finished with value: 0.9469964749886218 and parameters: {'n_estimators': 126, 'max_depth': 18}. Best is trial 44 with value: 0.9501425548916161.\n",
      "[I 2025-01-30 20:49:25,190] Trial 47 finished with value: 0.9190651789827605 and parameters: {'n_estimators': 16, 'max_depth': 15}. Best is trial 44 with value: 0.9501425548916161.\n",
      "[I 2025-01-30 20:57:32,425] Trial 48 finished with value: 0.9466904372394087 and parameters: {'n_estimators': 139, 'max_depth': 18}. Best is trial 44 with value: 0.9501425548916161.\n",
      "[I 2025-01-30 21:03:40,742] Trial 49 finished with value: 0.9406307368158109 and parameters: {'n_estimators': 127, 'max_depth': 16}. Best is trial 44 with value: 0.9501425548916161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved new Gradient Boosting model.\n",
      "Number of 0s (normal): 151976\n",
      "Number of 1s (attack): 78780\n",
      "                      Feature  Importance\n",
      "6            flashloan_in_usd    0.373155\n",
      "1           to_address_profit    0.255845\n",
      "2       highest_profit_in_usd    0.126713\n",
      "0         from_address_profit    0.120482\n",
      "4                 path_length    0.089563\n",
      "5             num_swap_events    0.028792\n",
      "3  highest_price_change_ratio    0.005450\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def gb_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    \n",
    "    # Use StratifiedKFold for stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=skf, n_jobs=-1, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Check if the model already exists\n",
    "if os.path.exists(f'Models/{threshold}/gradient_boosting_model_{threshold}.pkl'):\n",
    "    # Load the existing model\n",
    "    best_model = joblib.load(f'Models/{threshold}/gradient_boosting_model_{threshold}.pkl')\n",
    "    print(\"Loaded existing Gradient Boosting model.\")\n",
    "    best_params = best_model.get_params()\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "else: \n",
    "    # Optimize with Optuna\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(gb_objective, n_trials=50)\n",
    "\n",
    "    # Best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = GradientBoostingClassifier(**best_params, random_state=42)\n",
    "    # Save the model\n",
    "    joblib.dump(best_model, f'Models/{threshold}/gradient_boosting_model_{threshold}.pkl')\n",
    "    print(\"Trained and saved new Gradient Boosting model.\")\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate confusion matrix and AUC-ROC score\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame to store Precision-Recall data\n",
    "pr_data_df = pd.DataFrame({\n",
    "    'Recall': recall,\n",
    "    'Precision': precision\n",
    "})\n",
    "\n",
    "# Save the Precision-Recall data to a CSV file\n",
    "pr_data_df.to_csv('Models/gradient_boosting_precision_recall_data.csv', index=False)\n",
    "\n",
    "# Prepare confusion matrix data\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_list = [\n",
    "    {'Metric': 'True Negatives', 'Value': tn},\n",
    "    {'Metric': 'False Positives', 'Value': fp},\n",
    "    {'Metric': 'False Negatives', 'Value': fn},\n",
    "    {'Metric': 'True Positives', 'Value': tp},\n",
    "    {'Metric': 'AUC-ROC', 'Value': auc_roc}\n",
    "]\n",
    "\n",
    "# Add classification report data to the metrics DataFrame\n",
    "for label, metrics in class_report.items():\n",
    "    if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        metrics_list.append({'Metric': f'Precision ({label})', 'Value': metrics['precision']})\n",
    "        metrics_list.append({'Metric': f'Recall ({label})', 'Value': metrics['recall']})\n",
    "        metrics_list.append({'Metric': f'F1-Score ({label})', 'Value': metrics['f1-score']})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv('Models/gradient_boosting_metrics.csv', index=False)\n",
    "\n",
    "# Calculate ROC curve data\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame for ROC curve data\n",
    "roc_data_df = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr,\n",
    "    'Thresholds': thresholds\n",
    "})\n",
    "\n",
    "# Save ROC curve data to CSV\n",
    "roc_data_df.to_csv('Models/gradient_boosting_roc_data.csv', index=False)\n",
    "\n",
    "# Predict the labels for the unlabeled dataset\n",
    "gb_y_unlabeled_pred = best_model.predict(X_unlabeled_scaled)\n",
    "\n",
    "# Count the number of 0s and 1s in the predictions\n",
    "num_zeros = np.sum(gb_y_unlabeled_pred == 0)\n",
    "num_ones = np.sum(gb_y_unlabeled_pred == 1)\n",
    "\n",
    "print(f\"Number of 0s (normal): {num_zeros}\")\n",
    "print(f\"Number of 1s (attack): {num_ones}\")\n",
    "\n",
    "unlabeled['prediction'] = gb_y_unlabeled_pred\n",
    "platform_prediction_counts = unlabeled.groupby(['platform', 'prediction']).size().unstack(fill_value=0)\n",
    "platform_prediction_counts.to_csv('Models/gradient_boosting_unlabeled_platform_prediction_counts.csv')\n",
    "\n",
    "unlabeled_predictions['Gradient_Boosting'] = gb_y_unlabeled_pred\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03acfcbb",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1218dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 21:13:13,623] A new study created in memory with name: no-name-5b20e78e-0f6d-4335-baf9-0f2c653e59bc\n",
      "[I 2025-01-30 21:14:33,519] Trial 0 finished with value: 0.7155092416416393 and parameters: {'n_estimators': 313}. Best is trial 0 with value: 0.7155092416416393.\n",
      "[I 2025-01-30 21:15:35,746] Trial 1 finished with value: 0.7139147083452613 and parameters: {'n_estimators': 291}. Best is trial 0 with value: 0.7155092416416393.\n",
      "[I 2025-01-30 21:15:43,495] Trial 2 finished with value: 0.6146255902904904 and parameters: {'n_estimators': 30}. Best is trial 0 with value: 0.7155092416416393.\n",
      "[I 2025-01-30 21:16:16,534] Trial 3 finished with value: 0.6742628141815106 and parameters: {'n_estimators': 137}. Best is trial 0 with value: 0.7155092416416393.\n",
      "[I 2025-01-30 21:17:43,272] Trial 4 finished with value: 0.7212756111309053 and parameters: {'n_estimators': 387}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:18:25,070] Trial 5 finished with value: 0.6872378830116699 and parameters: {'n_estimators': 184}. Best is trial 4 with value: 0.7212756111309053.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[I 2025-01-30 21:19:11,321] Trial 6 finished with value: 0.6930661132933682 and parameters: {'n_estimators': 199}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:20:09,093] Trial 7 finished with value: 0.7136149332326935 and parameters: {'n_estimators': 289}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:20:20,124] Trial 8 finished with value: 0.6464080071950622 and parameters: {'n_estimators': 54}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:21:20,809] Trial 9 finished with value: 0.7148089669824068 and parameters: {'n_estimators': 308}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:22:37,935] Trial 10 finished with value: 0.7204091884495961 and parameters: {'n_estimators': 394}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:23:53,235] Trial 11 finished with value: 0.7200558699975719 and parameters: {'n_estimators': 380}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:25:17,665] Trial 12 finished with value: 0.7193834542754578 and parameters: {'n_estimators': 398}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:26:28,888] Trial 13 finished with value: 0.720162636987287 and parameters: {'n_estimators': 355}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:27:18,302] Trial 14 finished with value: 0.7052148196486041 and parameters: {'n_estimators': 245}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:28:27,102] Trial 15 finished with value: 0.7182633830150621 and parameters: {'n_estimators': 347}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:28:56,357] Trial 16 finished with value: 0.6735288068923703 and parameters: {'n_estimators': 117}. Best is trial 4 with value: 0.7212756111309053.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[I 2025-01-30 21:30:00,331] Trial 17 finished with value: 0.7064384086756178 and parameters: {'n_estimators': 248}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:31:09,582] Trial 18 finished with value: 0.718509348747126 and parameters: {'n_estimators': 348}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:32:28,973] Trial 19 finished with value: 0.7197927623352515 and parameters: {'n_estimators': 396}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:33:19,744] Trial 20 finished with value: 0.7055382156571746 and parameters: {'n_estimators': 247}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:34:30,013] Trial 21 finished with value: 0.7192822390119253 and parameters: {'n_estimators': 356}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:35:44,834] Trial 22 finished with value: 0.7184134945241013 and parameters: {'n_estimators': 358}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:36:48,884] Trial 23 finished with value: 0.7149981371081602 and parameters: {'n_estimators': 321}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:38:02,622] Trial 24 finished with value: 0.7196397977223787 and parameters: {'n_estimators': 369}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:39:10,293] Trial 25 finished with value: 0.7162974308965822 and parameters: {'n_estimators': 330}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:40:04,704] Trial 26 finished with value: 0.7096296316689104 and parameters: {'n_estimators': 276}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:41:26,909] Trial 27 finished with value: 0.7197927623352515 and parameters: {'n_estimators': 396}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:42:34,044] Trial 28 finished with value: 0.7170560071597128 and parameters: {'n_estimators': 337}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:43:48,916] Trial 29 finished with value: 0.7197229554819068 and parameters: {'n_estimators': 373}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:44:43,491] Trial 30 finished with value: 0.708085944975579 and parameters: {'n_estimators': 268}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:45:58,209] Trial 31 finished with value: 0.720161853136323 and parameters: {'n_estimators': 379}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:47:01,098] Trial 32 finished with value: 0.7151696355706756 and parameters: {'n_estimators': 303}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:48:16,596] Trial 33 finished with value: 0.7209358591896353 and parameters: {'n_estimators': 383}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:49:36,237] Trial 34 finished with value: 0.7193369829557981 and parameters: {'n_estimators': 400}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:50:43,617] Trial 35 finished with value: 0.7163813851235749 and parameters: {'n_estimators': 332}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:51:17,983] Trial 36 finished with value: 0.6842209407579997 and parameters: {'n_estimators': 173}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:52:34,934] Trial 37 finished with value: 0.7202576132400467 and parameters: {'n_estimators': 375}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:52:57,853] Trial 38 finished with value: 0.6722158298169036 and parameters: {'n_estimators': 111}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:54:04,397] Trial 39 finished with value: 0.7155092416416393 and parameters: {'n_estimators': 311}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:55:19,492] Trial 40 finished with value: 0.719744686113244 and parameters: {'n_estimators': 378}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:56:34,918] Trial 41 finished with value: 0.7192564694965403 and parameters: {'n_estimators': 366}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:57:48,198] Trial 42 finished with value: 0.718509348747126 and parameters: {'n_estimators': 348}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 21:59:04,346] Trial 43 finished with value: 0.7209358591896353 and parameters: {'n_estimators': 383}. Best is trial 4 with value: 0.7212756111309053.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[I 2025-01-30 22:00:21,196] Trial 44 finished with value: 0.720284033623501 and parameters: {'n_estimators': 384}. Best is trial 4 with value: 0.7212756111309053.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[I 2025-01-30 22:00:25,837] Trial 45 finished with value: 0.41823142277573727 and parameters: {'n_estimators': 11}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 22:01:25,441] Trial 46 finished with value: 0.7136149332326935 and parameters: {'n_estimators': 289}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 22:02:51,418] Trial 47 finished with value: 0.720207101688873 and parameters: {'n_estimators': 388}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 22:04:02,401] Trial 48 finished with value: 0.7170560071597128 and parameters: {'n_estimators': 337}. Best is trial 4 with value: 0.7212756111309053.\n",
      "[I 2025-01-30 22:04:47,929] Trial 49 finished with value: 0.6957888325982686 and parameters: {'n_estimators': 211}. Best is trial 4 with value: 0.7212756111309053.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and saved new AdaBoost model.\n",
      "Number of 0s (normal): 188323\n",
      "Number of 1s (attack): 42433\n",
      "                      Feature  Importance\n",
      "1           to_address_profit    0.410185\n",
      "6            flashloan_in_usd    0.273694\n",
      "0         from_address_profit    0.224647\n",
      "4                 path_length    0.077582\n",
      "5             num_swap_events    0.013892\n",
      "2       highest_profit_in_usd    0.000000\n",
      "3  highest_price_change_ratio    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def ab_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 400)\n",
    "    model = AdaBoostClassifier(n_estimators=n_estimators, algorithm='SAMME', random_state=42)\n",
    "    \n",
    "    # Use StratifiedKFold for stratified cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=skf, n_jobs=-1, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Check if the model already exists\n",
    "if os.path.exists(f'Models/{threshold}/adaboost_model_{threshold}.pkl'):\n",
    "    # Load the existing model\n",
    "    best_model = joblib.load(f'Models/{threshold}/adaboost_model_{threshold}.pkl')\n",
    "    print(\"Loaded existing AdaBoost model.\")\n",
    "    best_params = best_model.get_params()\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "else: \n",
    "    # Optimize with Optuna\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(ab_objective, n_trials=50)\n",
    "\n",
    "    # Best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = AdaBoostClassifier(**best_params, algorithm='SAMME', random_state=42)\n",
    "    # Save the model\n",
    "    joblib.dump(best_model, f'Models/{threshold}/adaboost_model_{threshold}.pkl')\n",
    "    print(\"Trained and saved new AdaBoost model.\")\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Calculate confusion matrix and AUC-ROC score\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Calculate classification report\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame to store Precision-Recall data\n",
    "pr_data_df = pd.DataFrame({\n",
    "    'Recall': recall,\n",
    "    'Precision': precision\n",
    "})\n",
    "\n",
    "# Save the Precision-Recall data to a CSV file\n",
    "pr_data_df.to_csv('Models/adaboost_precision_recall_data.csv', index=False)\n",
    "\n",
    "# Prepare confusion matrix data\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "metrics_list = [\n",
    "    {'Metric': 'True Negatives', 'Value': tn},\n",
    "    {'Metric': 'False Positives', 'Value': fp},\n",
    "    {'Metric': 'False Negatives', 'Value': fn},\n",
    "    {'Metric': 'True Positives', 'Value': tp},\n",
    "    {'Metric': 'AUC-ROC', 'Value': auc_roc}\n",
    "]\n",
    "\n",
    "# Add classification report data to the metrics DataFrame\n",
    "for label, metrics in class_report.items():\n",
    "    if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        metrics_list.append({'Metric': f'Precision ({label})', 'Value': metrics['precision']})\n",
    "        metrics_list.append({'Metric': f'Recall ({label})', 'Value': metrics['recall']})\n",
    "        metrics_list.append({'Metric': f'F1-Score ({label})', 'Value': metrics['f1-score']})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv('Models/adaboost_metrics.csv', index=False)\n",
    "\n",
    "# Calculate ROC curve data\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Create a DataFrame for ROC curve data\n",
    "roc_data_df = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr,\n",
    "    'Thresholds': thresholds\n",
    "})\n",
    "\n",
    "# Save ROC curve data to CSV\n",
    "roc_data_df.to_csv('Models/adaboost_roc_data.csv', index=False)\n",
    "\n",
    "# Predict the labels for the unlabeled dataset\n",
    "ada_y_unlabeled_pred = best_model.predict(X_unlabeled_scaled)\n",
    "\n",
    "# Count the number of 0s and 1s in the predictions\n",
    "num_zeros = np.sum(ada_y_unlabeled_pred == 0)\n",
    "num_ones = np.sum(ada_y_unlabeled_pred == 1)\n",
    "\n",
    "print(f\"Number of 0s (normal): {num_zeros}\")\n",
    "print(f\"Number of 1s (attack): {num_ones}\")\n",
    "\n",
    "unlabeled['prediction'] = ada_y_unlabeled_pred\n",
    "platform_prediction_counts = unlabeled.groupby(['platform', 'prediction']).size().unstack(fill_value=0)\n",
    "platform_prediction_counts.to_csv('Models/adaboost_unlabeled_platform_prediction_counts.csv')\n",
    "\n",
    "unlabeled_predictions['AdaBoost'] = ada_y_unlabeled_pred\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b78b5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled['Random_Forest'] = unlabeled_predictions['Random_Forest']\n",
    "unlabeled['KNN'] = unlabeled_predictions['KNN']\n",
    "unlabeled['Decision_Tree'] = unlabeled_predictions['Decision_Tree']\n",
    "unlabeled['Gradient_Boosting'] = unlabeled_predictions['Gradient_Boosting']\n",
    "unlabeled['AdaBoost'] = unlabeled_predictions['AdaBoost']\n",
    "unlabeled_predictions = unlabeled_predictions.astype(bool)\n",
    "unlabeled['All_Attack'] = unlabeled_predictions.sum(axis=1) == len(unlabeled_predictions.columns)\n",
    "unlabeled.to_csv('Models/unlabeled_all_models.csv', index=False)\n",
    "all_attack_indices = unlabeled[unlabeled['All_Attack']].index\n",
    "all_attack_data = unlabeled.loc[all_attack_indices]\n",
    "all_attack_data.to_csv('Models/unlabeled_all_attack_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
