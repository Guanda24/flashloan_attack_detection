{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d5f53f-40d0-4480-ae47-0c3d3471df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b265e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2107340/990185805.py:3: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unlabeled = pd.read_csv('/local/scratch/exported/MP_Defi_txs_TY_23/guanda/unlabeled.csv')\n",
      "/tmp/ipykernel_2107340/990185805.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  normal_label['label'] = 0\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "attack_label = pd.read_csv('/local/scratch/exported/MP_Defi_txs_TY_23/guanda/attack_label.csv')\n",
    "unlabeled = pd.read_csv('/local/scratch/exported/MP_Defi_txs_TY_23/guanda/unlabeled.csv')\n",
    "unlabeled['flashloan_in_usd'] = unlabeled['flashloan_in_usd'].astype(float)\n",
    "normal_label = unlabeled[unlabeled['highest_profit_in_usd'] <= 1000]\n",
    "test_set = unlabeled[unlabeled['highest_profit_in_usd'] > 1000]\n",
    "\n",
    "# Add a new column for labels: 1 for attack and 0 for normal\n",
    "attack_label['label'] = 1  # Attack\n",
    "normal_label['label'] = 0 \n",
    "\n",
    "# Combine the datasets\n",
    "combined_df = pd.concat([attack_label, normal_label], ignore_index=True)\n",
    "\n",
    "# Convert 'flashloan_in_usd' to numeric, coercing errors to NaN\n",
    "combined_df['flashloan_in_usd'] = pd.to_numeric(combined_df['flashloan_in_usd'], errors='coerce')\n",
    "\n",
    "# Select features\n",
    "features = ['from_address_profit', 'to_address_profit', 'highest_profit_in_usd',\n",
    "            'highest_price_change_ratio', 'path_length', 'num_swap_events', 'flashloan_in_usd']\n",
    "\n",
    "X = combined_df[features]\n",
    "y = combined_df['label']\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907af5c",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83543763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-03 15:39:09,306] A new study created in memory with name: no-name-972114a8-e766-4850-b630-a53f23139d1d\n",
      "[I 2024-10-03 15:39:50,665] Trial 0 finished with value: 0.6272415955720378 and parameters: {'n_estimators': 185, 'max_depth': 19, 'min_samples_split': 2}. Best is trial 0 with value: 0.6272415955720378.\n",
      "[I 2024-10-03 15:40:09,367] Trial 1 finished with value: 0.6269255882354642 and parameters: {'n_estimators': 81, 'max_depth': 18, 'min_samples_split': 8}. Best is trial 0 with value: 0.6272415955720378.\n",
      "[I 2024-10-03 15:40:21,018] Trial 2 finished with value: 0.6358822104532931 and parameters: {'n_estimators': 59, 'max_depth': 12, 'min_samples_split': 2}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:40:35,203] Trial 3 finished with value: 0.6205965017869571 and parameters: {'n_estimators': 89, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:40:44,389] Trial 4 finished with value: 0.20715107976506056 and parameters: {'n_estimators': 113, 'max_depth': 3, 'min_samples_split': 7}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:41:09,662] Trial 5 finished with value: 0.6259898864866767 and parameters: {'n_estimators': 113, 'max_depth': 20, 'min_samples_split': 8}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:41:16,225] Trial 6 finished with value: 0.5649293862157652 and parameters: {'n_estimators': 51, 'max_depth': 6, 'min_samples_split': 9}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:41:30,592] Trial 7 finished with value: 0.6274382550325839 and parameters: {'n_estimators': 64, 'max_depth': 18, 'min_samples_split': 4}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:41:38,956] Trial 8 finished with value: 0.6339736445354546 and parameters: {'n_estimators': 36, 'max_depth': 17, 'min_samples_split': 5}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:42:03,254] Trial 9 finished with value: 0.62804198869342 and parameters: {'n_estimators': 118, 'max_depth': 14, 'min_samples_split': 6}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:42:32,901] Trial 10 finished with value: 0.6338687753485719 and parameters: {'n_estimators': 163, 'max_depth': 12, 'min_samples_split': 2}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:42:35,513] Trial 11 finished with value: 0.6266645335883555 and parameters: {'n_estimators': 12, 'max_depth': 14, 'min_samples_split': 4}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:42:40,327] Trial 12 finished with value: 0.6280596229867335 and parameters: {'n_estimators': 23, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 2 with value: 0.6358822104532931.\n",
      "[I 2024-10-03 15:42:46,284] Trial 13 finished with value: 0.6379725262360783 and parameters: {'n_estimators': 38, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:42:54,264] Trial 14 finished with value: 0.6366453723068254 and parameters: {'n_estimators': 53, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:42:58,954] Trial 15 finished with value: 0.5992031189878168 and parameters: {'n_estimators': 37, 'max_depth': 7, 'min_samples_split': 3}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:43:04,166] Trial 16 finished with value: 0.0 and parameters: {'n_estimators': 144, 'max_depth': 1, 'min_samples_split': 3}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:43:16,893] Trial 17 finished with value: 0.6231371672982511 and parameters: {'n_estimators': 87, 'max_depth': 9, 'min_samples_split': 10}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:43:18,247] Trial 18 finished with value: 0.5093709054408958 and parameters: {'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:43:22,050] Trial 19 finished with value: 0.276595243601064 and parameters: {'n_estimators': 42, 'max_depth': 4, 'min_samples_split': 5}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:43:33,198] Trial 20 finished with value: 0.6264873136533176 and parameters: {'n_estimators': 70, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:43:43,181] Trial 21 finished with value: 0.6373302752331179 and parameters: {'n_estimators': 53, 'max_depth': 12, 'min_samples_split': 2}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:43:48,717] Trial 22 finished with value: 0.6302477448121 and parameters: {'n_estimators': 29, 'max_depth': 12, 'min_samples_split': 2}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:43:57,153] Trial 23 finished with value: 0.626210447299098 and parameters: {'n_estimators': 54, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:44:09,665] Trial 24 finished with value: 0.6060846294355643 and parameters: {'n_estimators': 99, 'max_depth': 7, 'min_samples_split': 2}. Best is trial 13 with value: 0.6379725262360783.\n",
      "[I 2024-10-03 15:44:22,283] Trial 25 finished with value: 0.639597168988815 and parameters: {'n_estimators': 74, 'max_depth': 11, 'min_samples_split': 3}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:44:35,223] Trial 26 finished with value: 0.6358706956519506 and parameters: {'n_estimators': 76, 'max_depth': 11, 'min_samples_split': 4}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:44:54,860] Trial 27 finished with value: 0.6325065564989839 and parameters: {'n_estimators': 98, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:45:18,932] Trial 28 finished with value: 0.6328130027553495 and parameters: {'n_estimators': 128, 'max_depth': 13, 'min_samples_split': 6}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:45:22,847] Trial 29 finished with value: 0.6259777844353882 and parameters: {'n_estimators': 22, 'max_depth': 11, 'min_samples_split': 3}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:45:37,421] Trial 30 finished with value: 0.636939298173375 and parameters: {'n_estimators': 71, 'max_depth': 16, 'min_samples_split': 4}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:46:18,297] Trial 31 finished with value: 0.6390508130919694 and parameters: {'n_estimators': 198, 'max_depth': 16, 'min_samples_split': 4}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:46:55,159] Trial 32 finished with value: 0.6311696633641588 and parameters: {'n_estimators': 197, 'max_depth': 13, 'min_samples_split': 2}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:47:21,523] Trial 33 finished with value: 0.6236929846717293 and parameters: {'n_estimators': 172, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:47:49,269] Trial 34 finished with value: 0.6345367880851096 and parameters: {'n_estimators': 133, 'max_depth': 17, 'min_samples_split': 5}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:48:01,543] Trial 35 finished with value: 0.6238991606859041 and parameters: {'n_estimators': 86, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:48:12,462] Trial 36 finished with value: 0.6303915697135106 and parameters: {'n_estimators': 46, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:48:24,768] Trial 37 finished with value: 0.6283464207556418 and parameters: {'n_estimators': 63, 'max_depth': 13, 'min_samples_split': 3}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:48:49,668] Trial 38 finished with value: 0.6226032375658785 and parameters: {'n_estimators': 150, 'max_depth': 11, 'min_samples_split': 2}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:49:06,130] Trial 39 finished with value: 0.47559765496053313 and parameters: {'n_estimators': 180, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:49:20,014] Trial 40 finished with value: 0.6283467326315288 and parameters: {'n_estimators': 63, 'max_depth': 19, 'min_samples_split': 7}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:49:37,404] Trial 41 finished with value: 0.6385733977909231 and parameters: {'n_estimators': 80, 'max_depth': 17, 'min_samples_split': 4}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:49:54,142] Trial 42 finished with value: 0.626911566572093 and parameters: {'n_estimators': 78, 'max_depth': 18, 'min_samples_split': 4}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:50:06,609] Trial 43 finished with value: 0.6335580511967518 and parameters: {'n_estimators': 57, 'max_depth': 16, 'min_samples_split': 5}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:50:27,539] Trial 44 finished with value: 0.6334308976516934 and parameters: {'n_estimators': 105, 'max_depth': 14, 'min_samples_split': 4}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:50:47,994] Trial 45 finished with value: 0.6275036353113156 and parameters: {'n_estimators': 97, 'max_depth': 18, 'min_samples_split': 3}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:50:57,827] Trial 46 finished with value: 0.6367439329579625 and parameters: {'n_estimators': 45, 'max_depth': 16, 'min_samples_split': 4}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:51:02,290] Trial 47 finished with value: 0.6177120348260481 and parameters: {'n_estimators': 30, 'max_depth': 8, 'min_samples_split': 8}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:51:15,099] Trial 48 finished with value: 0.6276837740694248 and parameters: {'n_estimators': 69, 'max_depth': 12, 'min_samples_split': 5}. Best is trial 25 with value: 0.639597168988815.\n",
      "[I 2024-10-03 15:51:32,714] Trial 49 finished with value: 0.6294507472674568 and parameters: {'n_estimators': 81, 'max_depth': 19, 'min_samples_split': 3}. Best is trial 25 with value: 0.639597168988815.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    281759\n",
      "           1       0.97      0.65      0.78      4476\n",
      "\n",
      "    accuracy                           0.99    286235\n",
      "   macro avg       0.98      0.83      0.89    286235\n",
      "weighted avg       0.99      0.99      0.99    286235\n",
      "\n",
      "Number of 1s (attacks): 2994\n",
      "Number of 0s (normals): 283241\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def rf_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                   min_samples_split=min_samples_split, random_state=42)\n",
    "    \n",
    "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(rf_objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_scaled, y)\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "print(\"Random Forest Classifier\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Number of 1s (attacks): {np.sum(y_pred == 1)}\")\n",
    "print(f\"Number of 0s (normals): {np.sum(y_pred == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6fda28",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8d4be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-03 20:28:01,878] A new study created in memory with name: no-name-774f7017-3c34-41d6-8b72-1e82f5577d22\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 20:31:34,935] Trial 0 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 2798}. Best is trial 0 with value: 0.007007337413077824.\n",
      "[I 2024-10-03 20:31:36,272] Trial 1 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4316}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:31:37,546] Trial 2 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4110}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:31:38,896] Trial 3 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 2173}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 20:34:33,659] Trial 4 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 2360}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 20:38:29,074] Trial 5 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 3109}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 20:43:05,139] Trial 6 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 3888}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 20:44:51,426] Trial 7 finished with value: 0.006567802848786083 and parameters: {'solver': 'saga', 'max_iter': 1438}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:44:54,518] Trial 8 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 3489}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 20:49:36,479] Trial 9 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 3940}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:43,478] Trial 10 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4736}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:44,724] Trial 11 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4904}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:45,937] Trial 12 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4244}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:47,162] Trial 13 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 147}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:47,945] Trial 14 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4415}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:49,473] Trial 15 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 3432}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:50,757] Trial 16 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 1532}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:52,472] Trial 17 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4985}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:53,695] Trial 18 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 3775}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:54,934] Trial 19 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4320}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:56,198] Trial 20 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 103}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:57,454] Trial 21 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 2110}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:58,691] Trial 22 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 1692}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:49:59,543] Trial 23 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 870}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:50:00,294] Trial 24 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 2867}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:50:01,885] Trial 25 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 2054}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:50:02,842] Trial 26 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 3431}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:50:03,798] Trial 27 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 2666}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:50:04,702] Trial 28 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 1127}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 20:53:47,612] Trial 29 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 3046}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:53:48,464] Trial 30 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4502}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:53:49,338] Trial 31 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 3432}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:53:50,373] Trial 32 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4040}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 20:53:51,323] Trial 33 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 3667}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 20:56:47,042] Trial 34 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 2369}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 21:00:41,526] Trial 35 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 3178}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:00:45,869] Trial 36 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4613}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 21:05:38,296] Trial 37 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 4128}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:05:44,793] Trial 38 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 3666}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 21:05:46,241] Trial 39 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 2468}. Best is trial 1 with value: 0.011813310059420008.\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-03 21:08:04,491] Trial 40 finished with value: 0.007007337413077824 and parameters: {'solver': 'saga', 'max_iter': 1933}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:05,741] Trial 41 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4716}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:07,084] Trial 42 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4743}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:08,290] Trial 43 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4289}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:09,509] Trial 44 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4039}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:10,802] Trial 45 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4779}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:12,063] Trial 46 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4470}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:13,311] Trial 47 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 5000}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:14,876] Trial 48 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 3824}. Best is trial 1 with value: 0.011813310059420008.\n",
      "[I 2024-10-03 21:08:16,121] Trial 49 finished with value: 0.011813310059420008 and parameters: {'solver': 'liblinear', 'max_iter': 4201}. Best is trial 1 with value: 0.011813310059420008.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    281759\n",
      "           1       0.09      0.01      0.01      4476\n",
      "\n",
      "    accuracy                           0.98    286235\n",
      "   macro avg       0.54      0.50      0.50    286235\n",
      "weighted avg       0.97      0.98      0.98    286235\n",
      "\n",
      "Number of 1s (attacks): 277\n",
      "Number of 0s (normals): 285958\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def lr_objective(trial):\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 5000)\n",
    "    model = LogisticRegression(solver=solver, max_iter=max_iter, random_state=42)\n",
    "    \n",
    "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lr_objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_model = LogisticRegression(**best_params, random_state=42)\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_scaled, y)\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "print(\"Logistic Regression\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Number of 1s (attacks): {np.sum(y_pred == 1)}\")\n",
    "print(f\"Number of 0s (normals): {np.sum(y_pred == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970ba3f",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8919a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-03 22:56:58,805] A new study created in memory with name: no-name-f8c26383-0033-4f93-9d63-0af5d99df1c5\n",
      "[W 2024-10-03 23:13:38,883] Trial 0 failed with parameters: {'C': 71.00269330396786} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_2107340/2756606407.py\", line 6, in svc_objective\n",
      "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 712, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 423, in cross_validate\n",
      "    results = parallel(\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"/home/user/gzhao/.local/lib/python3.9/site-packages/joblib/parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-03 23:13:38,885] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Optimize with Optuna\u001b[39;00m\n\u001b[1;32m     10\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvc_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Best parameters\u001b[39;00m\n\u001b[1;32m     14\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36msvc_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m C \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e2\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Tune C, the regularization strength\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SVC(C\u001b[38;5;241m=\u001b[39mC, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def svc_objective(trial):\n",
    "    C = trial.suggest_float(\"C\", 1e-5, 1e2, log=True)  # Tune C, the regularization strength\n",
    "    model = SVC(C=C, kernel='linear', random_state=42)\n",
    "    \n",
    "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(svc_objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_model = SVC(**best_params, kernel='linear', random_state=42)\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_scaled, y)\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "print(\"Support Vector Classifier\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Number of 1s (attacks): {np.sum(y_pred == 1)}\")\n",
    "print(f\"Number of 0s (normals): {np.sum(y_pred == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8e6c5",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce8a9f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-03 16:26:34,229] A new study created in memory with name: no-name-8d78cb29-517d-4ce8-8247-a5afd72c6cbe\n",
      "[I 2024-10-03 16:26:48,905] Trial 0 finished with value: 0.5068483972642754 and parameters: {'n_neighbors': 46, 'weights': 'distance'}. Best is trial 0 with value: 0.5068483972642754.\n",
      "[I 2024-10-03 16:26:53,078] Trial 1 finished with value: 0.5294913336377284 and parameters: {'n_neighbors': 12, 'weights': 'uniform'}. Best is trial 1 with value: 0.5294913336377284.\n",
      "[I 2024-10-03 16:26:58,161] Trial 2 finished with value: 0.45555887083307967 and parameters: {'n_neighbors': 45, 'weights': 'uniform'}. Best is trial 1 with value: 0.5294913336377284.\n",
      "[I 2024-10-03 16:27:03,054] Trial 3 finished with value: 0.5096373492662829 and parameters: {'n_neighbors': 42, 'weights': 'distance'}. Best is trial 1 with value: 0.5294913336377284.\n",
      "[I 2024-10-03 16:27:06,074] Trial 4 finished with value: 0.5371189617285504 and parameters: {'n_neighbors': 1, 'weights': 'uniform'}. Best is trial 4 with value: 0.5371189617285504.\n",
      "[I 2024-10-03 16:27:10,743] Trial 5 finished with value: 0.5058128996186836 and parameters: {'n_neighbors': 47, 'weights': 'distance'}. Best is trial 4 with value: 0.5371189617285504.\n",
      "[I 2024-10-03 16:27:14,344] Trial 6 finished with value: 0.5534744072429402 and parameters: {'n_neighbors': 4, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:18,775] Trial 7 finished with value: 0.5145652293855643 and parameters: {'n_neighbors': 38, 'weights': 'distance'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:23,182] Trial 8 finished with value: 0.520479399268359 and parameters: {'n_neighbors': 31, 'weights': 'distance'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:27,699] Trial 9 finished with value: 0.5155004620853567 and parameters: {'n_neighbors': 37, 'weights': 'distance'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:31,994] Trial 10 finished with value: 0.5147319425401717 and parameters: {'n_neighbors': 17, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:35,179] Trial 11 finished with value: 0.5371189617285504 and parameters: {'n_neighbors': 1, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:38,230] Trial 12 finished with value: 0.5371189617285504 and parameters: {'n_neighbors': 1, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:41,617] Trial 13 finished with value: 0.5472253980679189 and parameters: {'n_neighbors': 11, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:45,093] Trial 14 finished with value: 0.5294913336377284 and parameters: {'n_neighbors': 12, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:48,815] Trial 15 finished with value: 0.5003315219212071 and parameters: {'n_neighbors': 20, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:52,160] Trial 16 finished with value: 0.5432087059055329 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:56,284] Trial 17 finished with value: 0.47721190917081496 and parameters: {'n_neighbors': 27, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:27:59,490] Trial 18 finished with value: 0.5441716176958197 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:03,292] Trial 19 finished with value: 0.5003315219212071 and parameters: {'n_neighbors': 20, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:06,680] Trial 20 finished with value: 0.5405838912627167 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:09,888] Trial 21 finished with value: 0.5482314134902723 and parameters: {'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:13,130] Trial 22 finished with value: 0.5534744072429402 and parameters: {'n_neighbors': 4, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:16,320] Trial 23 finished with value: 0.5482314134902723 and parameters: {'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:20,130] Trial 24 finished with value: 0.5074099645866749 and parameters: {'n_neighbors': 16, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:23,061] Trial 25 finished with value: 0.5534744072429402 and parameters: {'n_neighbors': 4, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:26,913] Trial 26 finished with value: 0.519926716325668 and parameters: {'n_neighbors': 15, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:29,997] Trial 27 finished with value: 0.5482314134902723 and parameters: {'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:33,900] Trial 28 finished with value: 0.4848806889560363 and parameters: {'n_neighbors': 25, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:36,438] Trial 29 finished with value: 0.5437550491071781 and parameters: {'n_neighbors': 4, 'weights': 'distance'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:40,260] Trial 30 finished with value: 0.5003315219212071 and parameters: {'n_neighbors': 20, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:43,326] Trial 31 finished with value: 0.5534744072429402 and parameters: {'n_neighbors': 4, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:46,754] Trial 32 finished with value: 0.5429180265656297 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:50,323] Trial 33 finished with value: 0.5221570181200293 and parameters: {'n_neighbors': 13, 'weights': 'uniform'}. Best is trial 6 with value: 0.5534744072429402.\n",
      "[I 2024-10-03 16:28:53,281] Trial 34 finished with value: 0.5569106873340842 and parameters: {'n_neighbors': 3, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:28:56,607] Trial 35 finished with value: 0.5441716176958197 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:28:59,197] Trial 36 finished with value: 0.5371189617285504 and parameters: {'n_neighbors': 1, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:01,767] Trial 37 finished with value: 0.5416287284509879 and parameters: {'n_neighbors': 3, 'weights': 'distance'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:05,476] Trial 38 finished with value: 0.5432087059055329 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:08,624] Trial 39 finished with value: 0.5430479889898036 and parameters: {'n_neighbors': 13, 'weights': 'distance'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:11,919] Trial 40 finished with value: 0.5406452453503631 and parameters: {'n_neighbors': 6, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:14,860] Trial 41 finished with value: 0.5569106873340842 and parameters: {'n_neighbors': 3, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:17,620] Trial 42 finished with value: 0.5371189617285504 and parameters: {'n_neighbors': 1, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:22,342] Trial 43 finished with value: 0.44711320296042983 and parameters: {'n_neighbors': 50, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:25,923] Trial 44 finished with value: 0.5429180265656297 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:28,564] Trial 45 finished with value: 0.5393874434054068 and parameters: {'n_neighbors': 2, 'weights': 'distance'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:33,083] Trial 46 finished with value: 0.45775094562324625 and parameters: {'n_neighbors': 40, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:37,501] Trial 47 finished with value: 0.4580746332845772 and parameters: {'n_neighbors': 34, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:40,466] Trial 48 finished with value: 0.5569106873340842 and parameters: {'n_neighbors': 3, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n",
      "[I 2024-10-03 16:29:43,890] Trial 49 finished with value: 0.5441716176958197 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 34 with value: 0.5569106873340842.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    281759\n",
      "           1       0.92      0.76      0.83      4476\n",
      "\n",
      "    accuracy                           1.00    286235\n",
      "   macro avg       0.96      0.88      0.91    286235\n",
      "weighted avg       0.99      1.00      0.99    286235\n",
      "\n",
      "Number of 1s (attacks): 3702\n",
      "Number of 0s (normals): 282533\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 50)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "    \n",
    "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(knn_objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_model = KNeighborsClassifier(**best_params)\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_scaled, y)\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "print(\"K-Nearest Neighbors\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Number of 1s (attacks): {np.sum(y_pred == 1)}\")\n",
    "print(f\"Number of 0s (normals): {np.sum(y_pred == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320a541",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08b96102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-03 16:30:30,883] A new study created in memory with name: no-name-43369257-3eb3-44b2-aeab-71c89b8c4579\n",
      "[I 2024-10-03 16:30:32,203] Trial 0 finished with value: 0.5975301612219843 and parameters: {'max_depth': 13, 'min_samples_split': 6}. Best is trial 0 with value: 0.5975301612219843.\n",
      "[I 2024-10-03 16:30:33,125] Trial 1 finished with value: 0.4627810240508392 and parameters: {'max_depth': 4, 'min_samples_split': 10}. Best is trial 0 with value: 0.5975301612219843.\n",
      "[I 2024-10-03 16:30:34,308] Trial 2 finished with value: 0.5902268524103327 and parameters: {'max_depth': 12, 'min_samples_split': 6}. Best is trial 0 with value: 0.5975301612219843.\n",
      "[I 2024-10-03 16:30:35,613] Trial 3 finished with value: 0.5654927710720139 and parameters: {'max_depth': 20, 'min_samples_split': 7}. Best is trial 0 with value: 0.5975301612219843.\n",
      "[I 2024-10-03 16:30:36,799] Trial 4 finished with value: 0.5883440583155423 and parameters: {'max_depth': 15, 'min_samples_split': 4}. Best is trial 0 with value: 0.5975301612219843.\n",
      "[I 2024-10-03 16:30:37,800] Trial 5 finished with value: 0.5963465050774377 and parameters: {'max_depth': 11, 'min_samples_split': 8}. Best is trial 0 with value: 0.5975301612219843.\n",
      "[I 2024-10-03 16:30:38,333] Trial 6 finished with value: 0.5502313572320062 and parameters: {'max_depth': 3, 'min_samples_split': 10}. Best is trial 0 with value: 0.5975301612219843.\n",
      "[I 2024-10-03 16:30:39,175] Trial 7 finished with value: 0.6227124411867342 and parameters: {'max_depth': 8, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:39,760] Trial 8 finished with value: 0.4627810240508392 and parameters: {'max_depth': 4, 'min_samples_split': 4}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:40,960] Trial 9 finished with value: 0.5842294579159154 and parameters: {'max_depth': 15, 'min_samples_split': 6}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:41,809] Trial 10 finished with value: 0.6003552561516485 and parameters: {'max_depth': 7, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:42,627] Trial 11 finished with value: 0.6003552561516485 and parameters: {'max_depth': 7, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:43,457] Trial 12 finished with value: 0.6227124411867342 and parameters: {'max_depth': 8, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:44,344] Trial 13 finished with value: 0.6187736660622024 and parameters: {'max_depth': 8, 'min_samples_split': 4}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:44,807] Trial 14 finished with value: 0.01453732177802628 and parameters: {'max_depth': 1, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:45,696] Trial 15 finished with value: 0.6186827193293425 and parameters: {'max_depth': 9, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:46,442] Trial 16 finished with value: 0.6151520629234545 and parameters: {'max_depth': 6, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:47,399] Trial 17 finished with value: 0.6009797681444307 and parameters: {'max_depth': 10, 'min_samples_split': 5}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:48,740] Trial 18 finished with value: 0.583232125930569 and parameters: {'max_depth': 17, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:49,466] Trial 19 finished with value: 0.598467158721415 and parameters: {'max_depth': 5, 'min_samples_split': 8}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:49,879] Trial 20 finished with value: 0.01453732177802628 and parameters: {'max_depth': 1, 'min_samples_split': 5}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:50,797] Trial 21 finished with value: 0.6187736660622024 and parameters: {'max_depth': 8, 'min_samples_split': 4}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:51,697] Trial 22 finished with value: 0.6186827193293425 and parameters: {'max_depth': 9, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:52,646] Trial 23 finished with value: 0.6037646888947158 and parameters: {'max_depth': 10, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:53,515] Trial 24 finished with value: 0.6003552561516485 and parameters: {'max_depth': 7, 'min_samples_split': 4}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:54,588] Trial 25 finished with value: 0.5968697310819736 and parameters: {'max_depth': 13, 'min_samples_split': 5}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:55,606] Trial 26 finished with value: 0.6186827193293425 and parameters: {'max_depth': 9, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:56,445] Trial 27 finished with value: 0.6151520629234545 and parameters: {'max_depth': 6, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:57,476] Trial 28 finished with value: 0.5976321644533082 and parameters: {'max_depth': 11, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:58,012] Trial 29 finished with value: 0.5502313572320062 and parameters: {'max_depth': 3, 'min_samples_split': 5}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:30:59,204] Trial 30 finished with value: 0.592218718668444 and parameters: {'max_depth': 14, 'min_samples_split': 4}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:00,045] Trial 31 finished with value: 0.6187736660622024 and parameters: {'max_depth': 8, 'min_samples_split': 4}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:00,899] Trial 32 finished with value: 0.6227124411867342 and parameters: {'max_depth': 8, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:01,587] Trial 33 finished with value: 0.598467158721415 and parameters: {'max_depth': 5, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:02,730] Trial 34 finished with value: 0.5988144685149293 and parameters: {'max_depth': 12, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:03,620] Trial 35 finished with value: 0.6227124411867342 and parameters: {'max_depth': 8, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:04,480] Trial 36 finished with value: 0.6151520629234545 and parameters: {'max_depth': 6, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:05,571] Trial 37 finished with value: 0.5884885136618927 and parameters: {'max_depth': 12, 'min_samples_split': 7}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:06,519] Trial 38 finished with value: 0.6037646888947158 and parameters: {'max_depth': 10, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:07,821] Trial 39 finished with value: 0.5793326063065682 and parameters: {'max_depth': 20, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:08,418] Trial 40 finished with value: 0.4627810240508392 and parameters: {'max_depth': 4, 'min_samples_split': 9}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:09,257] Trial 41 finished with value: 0.6227124411867342 and parameters: {'max_depth': 8, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:10,287] Trial 42 finished with value: 0.6227124411867342 and parameters: {'max_depth': 8, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:11,291] Trial 43 finished with value: 0.6003552561516485 and parameters: {'max_depth': 7, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:12,244] Trial 44 finished with value: 0.6186827193293425 and parameters: {'max_depth': 9, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:13,465] Trial 45 finished with value: 0.5976321644533082 and parameters: {'max_depth': 11, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:14,276] Trial 46 finished with value: 0.598467158721415 and parameters: {'max_depth': 5, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:15,075] Trial 47 finished with value: 0.6003552561516485 and parameters: {'max_depth': 7, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:15,965] Trial 48 finished with value: 0.6227124411867342 and parameters: {'max_depth': 8, 'min_samples_split': 2}. Best is trial 7 with value: 0.6227124411867342.\n",
      "[I 2024-10-03 16:31:16,502] Trial 49 finished with value: 0.5502313572320062 and parameters: {'max_depth': 3, 'min_samples_split': 3}. Best is trial 7 with value: 0.6227124411867342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    281759\n",
      "           1       0.91      0.63      0.74      4476\n",
      "\n",
      "    accuracy                           0.99    286235\n",
      "   macro avg       0.95      0.82      0.87    286235\n",
      "weighted avg       0.99      0.99      0.99    286235\n",
      "\n",
      "Number of 1s (attacks): 3126\n",
      "Number of 0s (normals): 283109\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def dt_objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "    \n",
    "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(dt_objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_scaled, y)\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "print(\"Decision Tree Classifier\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Number of 1s (attacks): {np.sum(y_pred == 1)}\")\n",
    "print(f\"Number of 0s (normals): {np.sum(y_pred == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbdad9c",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec17a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-03 17:58:36,144] A new study created in memory with name: no-name-325e1d7c-2cee-4e3e-b824-9a8f60bb55c4\n",
      "[I 2024-10-03 18:03:34,122] Trial 0 finished with value: 0.5972298483842005 and parameters: {'n_estimators': 158, 'max_depth': 18}. Best is trial 0 with value: 0.5972298483842005.\n",
      "[I 2024-10-03 18:06:19,835] Trial 1 finished with value: 0.5965094572595899 and parameters: {'n_estimators': 118, 'max_depth': 16}. Best is trial 0 with value: 0.5972298483842005.\n",
      "[I 2024-10-03 18:07:05,329] Trial 2 finished with value: 0.6071638498166216 and parameters: {'n_estimators': 48, 'max_depth': 11}. Best is trial 2 with value: 0.6071638498166216.\n",
      "[I 2024-10-03 18:12:02,311] Trial 3 finished with value: 0.593786293583489 and parameters: {'n_estimators': 180, 'max_depth': 17}. Best is trial 2 with value: 0.6071638498166216.\n",
      "[I 2024-10-03 18:12:25,218] Trial 4 finished with value: 0.6302161645924254 and parameters: {'n_estimators': 92, 'max_depth': 2}. Best is trial 4 with value: 0.6302161645924254.\n",
      "[I 2024-10-03 18:12:36,955] Trial 5 finished with value: 0.6326275304586774 and parameters: {'n_estimators': 48, 'max_depth': 3}. Best is trial 5 with value: 0.6326275304586774.\n",
      "[I 2024-10-03 18:14:49,994] Trial 6 finished with value: 0.6085389634801919 and parameters: {'n_estimators': 187, 'max_depth': 10}. Best is trial 5 with value: 0.6326275304586774.\n",
      "[I 2024-10-03 18:16:16,330] Trial 7 finished with value: 0.5971402614471911 and parameters: {'n_estimators': 99, 'max_depth': 12}. Best is trial 5 with value: 0.6326275304586774.\n",
      "[I 2024-10-03 18:16:19,451] Trial 8 finished with value: 0.2867739717537634 and parameters: {'n_estimators': 14, 'max_depth': 2}. Best is trial 5 with value: 0.6326275304586774.\n",
      "[I 2024-10-03 18:18:57,761] Trial 9 finished with value: 0.5964447605936094 and parameters: {'n_estimators': 113, 'max_depth': 16}. Best is trial 5 with value: 0.6326275304586774.\n",
      "[I 2024-10-03 18:19:27,190] Trial 10 finished with value: 0.6377496922738227 and parameters: {'n_estimators': 53, 'max_depth': 6}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:19:49,377] Trial 11 finished with value: 0.6377496922738227 and parameters: {'n_estimators': 53, 'max_depth': 6}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:20:14,671] Trial 12 finished with value: 0.6354847418126719 and parameters: {'n_estimators': 60, 'max_depth': 6}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:20:23,710] Trial 13 finished with value: 0.6244530183833553 and parameters: {'n_estimators': 18, 'max_depth': 7}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:20:55,303] Trial 14 finished with value: 0.6355486029543125 and parameters: {'n_estimators': 72, 'max_depth': 6}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:21:13,785] Trial 15 finished with value: 0.6158483563995553 and parameters: {'n_estimators': 32, 'max_depth': 8}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:21:37,120] Trial 16 finished with value: 0.6317836505174877 and parameters: {'n_estimators': 78, 'max_depth': 4}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:23:59,808] Trial 17 finished with value: 0.6074658569485866 and parameters: {'n_estimators': 128, 'max_depth': 14}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:24:25,326] Trial 18 finished with value: 0.623442378076847 and parameters: {'n_estimators': 38, 'max_depth': 9}. Best is trial 10 with value: 0.6377496922738227.\n",
      "[I 2024-10-03 18:24:53,584] Trial 19 finished with value: 0.6447009330618588 and parameters: {'n_estimators': 70, 'max_depth': 5}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:25:33,950] Trial 20 finished with value: 0.6395600793984774 and parameters: {'n_estimators': 142, 'max_depth': 4}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:26:16,348] Trial 21 finished with value: 0.6399359688349834 and parameters: {'n_estimators': 149, 'max_depth': 4}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:26:29,812] Trial 22 finished with value: 0.5086520278317602 and parameters: {'n_estimators': 152, 'max_depth': 1}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:30:56,496] Trial 23 finished with value: 0.5917347055801422 and parameters: {'n_estimators': 141, 'max_depth': 20}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:31:50,215] Trial 24 finished with value: 0.6405469704130581 and parameters: {'n_estimators': 162, 'max_depth': 4}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:32:40,448] Trial 25 finished with value: 0.6402543032764131 and parameters: {'n_estimators': 169, 'max_depth': 4}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:33:29,817] Trial 26 finished with value: 0.6402543032764131 and parameters: {'n_estimators': 169, 'max_depth': 4}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:33:48,111] Trial 27 finished with value: 0.5204512661079157 and parameters: {'n_estimators': 195, 'max_depth': 1}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:35:23,644] Trial 28 finished with value: 0.618000856725314 and parameters: {'n_estimators': 170, 'max_depth': 8}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:36:23,596] Trial 29 finished with value: 0.6443592346873566 and parameters: {'n_estimators': 165, 'max_depth': 5}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:38:39,348] Trial 30 finished with value: 0.6034990988884907 and parameters: {'n_estimators': 133, 'max_depth': 13}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:39:41,800] Trial 31 finished with value: 0.6438305930970738 and parameters: {'n_estimators': 167, 'max_depth': 5}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:40:38,066] Trial 32 finished with value: 0.6442646814514712 and parameters: {'n_estimators': 160, 'max_depth': 5}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:42:30,584] Trial 33 finished with value: 0.6146781483113606 and parameters: {'n_estimators': 199, 'max_depth': 8}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:43:38,373] Trial 34 finished with value: 0.643429547277068 and parameters: {'n_estimators': 182, 'max_depth': 5}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:45:03,649] Trial 35 finished with value: 0.6022501665174183 and parameters: {'n_estimators': 120, 'max_depth': 10}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:45:19,685] Trial 36 finished with value: 0.628553474210783 and parameters: {'n_estimators': 84, 'max_depth': 2}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:46:35,609] Trial 37 finished with value: 0.6286874467588547 and parameters: {'n_estimators': 157, 'max_depth': 7}. Best is trial 19 with value: 0.6447009330618588.\n",
      "[I 2024-10-03 18:47:14,723] Trial 38 finished with value: 0.6462119445076131 and parameters: {'n_estimators': 106, 'max_depth': 5}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:47:38,077] Trial 39 finished with value: 0.6456942335645257 and parameters: {'n_estimators': 98, 'max_depth': 3}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:47:56,245] Trial 40 finished with value: 0.6320445495276829 and parameters: {'n_estimators': 103, 'max_depth': 2}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:48:16,910] Trial 41 finished with value: 0.6460990553142691 and parameters: {'n_estimators': 90, 'max_depth': 3}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:48:38,389] Trial 42 finished with value: 0.6457649969894492 and parameters: {'n_estimators': 89, 'max_depth': 3}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:49:00,280] Trial 43 finished with value: 0.6460026159306506 and parameters: {'n_estimators': 91, 'max_depth': 3}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:49:23,218] Trial 44 finished with value: 0.6458843259917242 and parameters: {'n_estimators': 93, 'max_depth': 3}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:49:45,265] Trial 45 finished with value: 0.6460026159306506 and parameters: {'n_estimators': 91, 'max_depth': 3}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:49:54,680] Trial 46 finished with value: 0.43905564813810816 and parameters: {'n_estimators': 109, 'max_depth': 1}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:50:08,958] Trial 47 finished with value: 0.6292743243116896 and parameters: {'n_estimators': 93, 'max_depth': 2}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:50:34,868] Trial 48 finished with value: 0.6411837283233863 and parameters: {'n_estimators': 116, 'max_depth': 3}. Best is trial 38 with value: 0.6462119445076131.\n",
      "[I 2024-10-03 18:50:49,563] Trial 49 finished with value: 0.6433854316101246 and parameters: {'n_estimators': 64, 'max_depth': 3}. Best is trial 38 with value: 0.6462119445076131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    281759\n",
      "           1       0.94      0.68      0.79      4476\n",
      "\n",
      "    accuracy                           0.99    286235\n",
      "   macro avg       0.97      0.84      0.89    286235\n",
      "weighted avg       0.99      0.99      0.99    286235\n",
      "\n",
      "Number of 1s (attacks): 3255\n",
      "Number of 0s (normals): 282980\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def gb_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    \n",
    "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(gb_objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_model = GradientBoostingClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_scaled, y)\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "print(\"Gradient Boosting Classifier\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Number of 1s (attacks): {np.sum(y_pred == 1)}\")\n",
    "print(f\"Number of 0s (normals): {np.sum(y_pred == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03acfcbb",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1218dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-03 19:41:45,376] A new study created in memory with name: no-name-0b603743-e5b4-4213-8f8c-d8a102ba96c4\n",
      "[I 2024-10-03 19:42:07,700] Trial 0 finished with value: 0.36430585263464604 and parameters: {'n_estimators': 104}. Best is trial 0 with value: 0.36430585263464604.\n",
      "[I 2024-10-03 19:42:33,854] Trial 1 finished with value: 0.4171036801845848 and parameters: {'n_estimators': 217}. Best is trial 1 with value: 0.4171036801845848.\n",
      "[I 2024-10-03 19:43:15,083] Trial 2 finished with value: 0.5228784369904179 and parameters: {'n_estimators': 351}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:43:35,157] Trial 3 finished with value: 0.3713510278460245 and parameters: {'n_estimators': 163}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:43:41,531] Trial 4 finished with value: 0.2535512120278086 and parameters: {'n_estimators': 48}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:44:13,315] Trial 5 finished with value: 0.5145597120128719 and parameters: {'n_estimators': 266}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:44:18,815] Trial 6 finished with value: 0.2563732101137861 and parameters: {'n_estimators': 40}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:44:40,714] Trial 7 finished with value: 0.3860091067091322 and parameters: {'n_estimators': 167}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:44:43,676] Trial 8 finished with value: 0.22112376715907928 and parameters: {'n_estimators': 17}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:45:11,994] Trial 9 finished with value: 0.3976959631179465 and parameters: {'n_estimators': 221}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:46:03,165] Trial 10 finished with value: 0.5186563280056753 and parameters: {'n_estimators': 390}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:46:55,913] Trial 11 finished with value: 0.5191466147732778 and parameters: {'n_estimators': 399}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:47:31,782] Trial 12 finished with value: 0.5193716674807879 and parameters: {'n_estimators': 386}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:48:01,812] Trial 13 finished with value: 0.5200007222803051 and parameters: {'n_estimators': 322}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:48:30,965] Trial 14 finished with value: 0.5195180725167925 and parameters: {'n_estimators': 313}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:49:00,709] Trial 15 finished with value: 0.5195390598270252 and parameters: {'n_estimators': 319}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:49:31,958] Trial 16 finished with value: 0.519840274121501 and parameters: {'n_estimators': 332}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:49:57,281] Trial 17 finished with value: 0.5145597120128719 and parameters: {'n_estimators': 266}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:50:29,862] Trial 18 finished with value: 0.519947954497772 and parameters: {'n_estimators': 345}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:50:55,218] Trial 19 finished with value: 0.5153082848284102 and parameters: {'n_estimators': 274}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:51:28,000] Trial 20 finished with value: 0.5207516306624258 and parameters: {'n_estimators': 356}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:52:10,964] Trial 21 finished with value: 0.5196009547758706 and parameters: {'n_estimators': 348}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:52:44,779] Trial 22 finished with value: 0.5183393808532288 and parameters: {'n_estimators': 296}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:53:18,977] Trial 23 finished with value: 0.5198972754343434 and parameters: {'n_estimators': 363}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:53:51,755] Trial 24 finished with value: 0.5217468886024569 and parameters: {'n_estimators': 361}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:54:25,335] Trial 25 finished with value: 0.5220433793780923 and parameters: {'n_estimators': 365}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:54:51,899] Trial 26 finished with value: 0.5149676269624096 and parameters: {'n_estimators': 285}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:55:14,832] Trial 27 finished with value: 0.5109345344612262 and parameters: {'n_estimators': 242}. Best is trial 2 with value: 0.5228784369904179.\n",
      "[I 2024-10-03 19:55:49,785] Trial 28 finished with value: 0.5245494854046375 and parameters: {'n_estimators': 372}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 19:56:01,463] Trial 29 finished with value: 0.3720986117953772 and parameters: {'n_estimators': 123}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 19:56:35,554] Trial 30 finished with value: 0.5233618920757162 and parameters: {'n_estimators': 373}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 19:57:09,948] Trial 31 finished with value: 0.5231652344523736 and parameters: {'n_estimators': 376}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 19:57:44,535] Trial 32 finished with value: 0.5182316285055041 and parameters: {'n_estimators': 378}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 19:58:31,136] Trial 33 finished with value: 0.5191466147732778 and parameters: {'n_estimators': 399}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 19:58:59,832] Trial 34 finished with value: 0.5196563538703873 and parameters: {'n_estimators': 304}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 19:59:31,018] Trial 35 finished with value: 0.5204041016396399 and parameters: {'n_estimators': 338}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 19:59:48,904] Trial 36 finished with value: 0.3946795287870787 and parameters: {'n_estimators': 187}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:00:08,795] Trial 37 finished with value: 0.3711366359765674 and parameters: {'n_estimators': 117}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:00:43,303] Trial 38 finished with value: 0.5233618920757162 and parameters: {'n_estimators': 373}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:01:19,114] Trial 39 finished with value: 0.5231652344523736 and parameters: {'n_estimators': 376}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:01:41,555] Trial 40 finished with value: 0.4127787082787212 and parameters: {'n_estimators': 228}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:02:16,429] Trial 41 finished with value: 0.5224259057147582 and parameters: {'n_estimators': 374}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:02:47,128] Trial 42 finished with value: 0.5197527717357396 and parameters: {'n_estimators': 334}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:03:22,197] Trial 43 finished with value: 0.5198378650809126 and parameters: {'n_estimators': 381}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:04:51,181] Trial 44 finished with value: 0.5191466147732778 and parameters: {'n_estimators': 397}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:05:28,387] Trial 45 finished with value: 0.5231652344523736 and parameters: {'n_estimators': 376}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:05:36,741] Trial 46 finished with value: 0.3533257691178325 and parameters: {'n_estimators': 86}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:06:35,913] Trial 47 finished with value: 0.5196009547758706 and parameters: {'n_estimators': 348}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:07:07,340] Trial 48 finished with value: 0.5197527717357396 and parameters: {'n_estimators': 323}. Best is trial 28 with value: 0.5245494854046375.\n",
      "[I 2024-10-03 20:07:36,385] Trial 49 finished with value: 0.5195180725167925 and parameters: {'n_estimators': 309}. Best is trial 28 with value: 0.5245494854046375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    281759\n",
      "           1       0.75      0.47      0.58      4476\n",
      "\n",
      "    accuracy                           0.99    286235\n",
      "   macro avg       0.87      0.73      0.79    286235\n",
      "weighted avg       0.99      0.99      0.99    286235\n",
      "\n",
      "Number of 1s (attacks): 2800\n",
      "Number of 0s (normals): 283435\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def ab_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 400)\n",
    "    model = AdaBoostClassifier(n_estimators=n_estimators, algorithm='SAMME', random_state=42)\n",
    "    \n",
    "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(ab_objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_model = AdaBoostClassifier(**best_params, algorithm='SAMME', random_state=42)\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_scaled, y)\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "print(\"AdaBoost Classifier\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Number of 1s (attacks): {np.sum(y_pred == 1)}\")\n",
    "print(f\"Number of 0s (normals): {np.sum(y_pred == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6300a4a",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e225dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-03 19:27:04,153] A new study created in memory with name: no-name-c9bdbe6b-b334-4fed-bcca-a08b3289ec34\n",
      "[I 2024-10-03 19:27:18,996] Trial 0 finished with value: 0.5912829892948225 and parameters: {'n_estimators': 162, 'max_depth': 16}. Best is trial 0 with value: 0.5912829892948225.\n",
      "[I 2024-10-03 19:27:22,913] Trial 1 finished with value: 0.5917694729351379 and parameters: {'n_estimators': 151, 'max_depth': 17}. Best is trial 1 with value: 0.5917694729351379.\n",
      "[I 2024-10-03 19:27:25,335] Trial 2 finished with value: 0.5978019001638423 and parameters: {'n_estimators': 90, 'max_depth': 13}. Best is trial 2 with value: 0.5978019001638423.\n",
      "[I 2024-10-03 19:27:27,184] Trial 3 finished with value: 0.6083715023357927 and parameters: {'n_estimators': 92, 'max_depth': 6}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:28,696] Trial 4 finished with value: 0.6070936195229233 and parameters: {'n_estimators': 31, 'max_depth': 11}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:30,480] Trial 5 finished with value: 0.600724128328374 and parameters: {'n_estimators': 120, 'max_depth': 3}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:31,991] Trial 6 finished with value: 0.6068530359993876 and parameters: {'n_estimators': 48, 'max_depth': 6}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:36,152] Trial 7 finished with value: 0.5924424721912389 and parameters: {'n_estimators': 199, 'max_depth': 13}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:37,932] Trial 8 finished with value: 0.601855636268914 and parameters: {'n_estimators': 40, 'max_depth': 14}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:40,021] Trial 9 finished with value: 0.593421271448214 and parameters: {'n_estimators': 51, 'max_depth': 19}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:41,946] Trial 10 finished with value: 0.6068860232475246 and parameters: {'n_estimators': 90, 'max_depth': 7}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:43,232] Trial 11 finished with value: 0.600718871802468 and parameters: {'n_estimators': 10, 'max_depth': 9}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:44,247] Trial 12 finished with value: 0.16366939616878495 and parameters: {'n_estimators': 10, 'max_depth': 1}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:45,767] Trial 13 finished with value: 0.6054968585354821 and parameters: {'n_estimators': 72, 'max_depth': 10}. Best is trial 3 with value: 0.6083715023357927.\n",
      "[I 2024-10-03 19:27:47,337] Trial 14 finished with value: 0.6181659619960657 and parameters: {'n_estimators': 115, 'max_depth': 5}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:27:48,900] Trial 15 finished with value: 0.617572958706823 and parameters: {'n_estimators': 122, 'max_depth': 5}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:27:50,896] Trial 16 finished with value: 0.6008000423978397 and parameters: {'n_estimators': 121, 'max_depth': 3}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:27:53,425] Trial 17 finished with value: 0.6147469730048739 and parameters: {'n_estimators': 143, 'max_depth': 4}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:27:56,164] Trial 18 finished with value: 0.6018039739312874 and parameters: {'n_estimators': 179, 'max_depth': 8}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:27:57,595] Trial 19 finished with value: 0.49635202794976097 and parameters: {'n_estimators': 124, 'max_depth': 1}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:27:59,358] Trial 20 finished with value: 0.6154243474149388 and parameters: {'n_estimators': 139, 'max_depth': 5}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:28:01,583] Trial 21 finished with value: 0.6166119763235935 and parameters: {'n_estimators': 135, 'max_depth': 5}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:28:02,859] Trial 22 finished with value: 0.6031302512898821 and parameters: {'n_estimators': 108, 'max_depth': 3}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:28:05,366] Trial 23 finished with value: 0.6039695754502331 and parameters: {'n_estimators': 163, 'max_depth': 8}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:28:07,489] Trial 24 finished with value: 0.6168096268067949 and parameters: {'n_estimators': 133, 'max_depth': 5}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:28:08,676] Trial 25 finished with value: 0.5992312946626297 and parameters: {'n_estimators': 106, 'max_depth': 2}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:28:11,569] Trial 26 finished with value: 0.599382856578335 and parameters: {'n_estimators': 160, 'max_depth': 11}. Best is trial 14 with value: 0.6181659619960657.\n",
      "[I 2024-10-03 19:28:12,727] Trial 27 finished with value: 0.619472196132155 and parameters: {'n_estimators': 72, 'max_depth': 5}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:14,237] Trial 28 finished with value: 0.6067352490625207 and parameters: {'n_estimators': 71, 'max_depth': 7}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:15,699] Trial 29 finished with value: 0.6075084963754736 and parameters: {'n_estimators': 71, 'max_depth': 8}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:17,018] Trial 30 finished with value: 0.6157663702261609 and parameters: {'n_estimators': 84, 'max_depth': 4}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:18,854] Trial 31 finished with value: 0.617926315587108 and parameters: {'n_estimators': 110, 'max_depth': 5}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:20,458] Trial 32 finished with value: 0.6118017068211749 and parameters: {'n_estimators': 110, 'max_depth': 6}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:22,263] Trial 33 finished with value: 0.6153053666459642 and parameters: {'n_estimators': 98, 'max_depth': 4}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:23,366] Trial 34 finished with value: 0.5879717803667898 and parameters: {'n_estimators': 81, 'max_depth': 2}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:24,927] Trial 35 finished with value: 0.6055038310239248 and parameters: {'n_estimators': 62, 'max_depth': 7}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:27,018] Trial 36 finished with value: 0.6005598105789238 and parameters: {'n_estimators': 117, 'max_depth': 9}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:28,663] Trial 37 finished with value: 0.6100100188466068 and parameters: {'n_estimators': 102, 'max_depth': 6}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:30,147] Trial 38 finished with value: 0.6032554804001422 and parameters: {'n_estimators': 154, 'max_depth': 2}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:32,197] Trial 39 finished with value: 0.5997715005200057 and parameters: {'n_estimators': 93, 'max_depth': 12}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:35,825] Trial 40 finished with value: 0.5925586058114426 and parameters: {'n_estimators': 126, 'max_depth': 17}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:37,765] Trial 41 finished with value: 0.6172974573654485 and parameters: {'n_estimators': 129, 'max_depth': 5}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:39,421] Trial 42 finished with value: 0.61774548325765 and parameters: {'n_estimators': 113, 'max_depth': 5}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:40,744] Trial 43 finished with value: 0.60305763730738 and parameters: {'n_estimators': 116, 'max_depth': 3}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:42,448] Trial 44 finished with value: 0.6115727714650177 and parameters: {'n_estimators': 111, 'max_depth': 6}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:44,080] Trial 45 finished with value: 0.6145481571745242 and parameters: {'n_estimators': 144, 'max_depth': 4}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:45,694] Trial 46 finished with value: 0.6099196891073978 and parameters: {'n_estimators': 82, 'max_depth': 7}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:48,404] Trial 47 finished with value: 0.5897767708625293 and parameters: {'n_estimators': 98, 'max_depth': 20}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:49,503] Trial 48 finished with value: 0.6076595285861803 and parameters: {'n_estimators': 32, 'max_depth': 9}. Best is trial 27 with value: 0.619472196132155.\n",
      "[I 2024-10-03 19:28:51,289] Trial 49 finished with value: 0.5992815136574235 and parameters: {'n_estimators': 59, 'max_depth': 15}. Best is trial 27 with value: 0.619472196132155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    281759\n",
      "           1       0.92      0.68      0.78      4476\n",
      "\n",
      "    accuracy                           0.99    286235\n",
      "   macro avg       0.96      0.84      0.89    286235\n",
      "weighted avg       0.99      0.99      0.99    286235\n",
      "\n",
      "Number of 1s (attacks): 3306\n",
      "Number of 0s (normals): 282929\n"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def xgb_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    \n",
    "    model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, eval_metric='logloss', random_state=42)\n",
    "    \n",
    "    score = cross_val_score(model, X_scaled, y, n_jobs=-1, cv=10, scoring='f1').mean()\n",
    "    return score\n",
    "\n",
    "# Optimize with Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(xgb_objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_model = XGBClassifier(**best_params, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Fit and evaluate\n",
    "best_model.fit(X_scaled, y)\n",
    "y_pred = best_model.predict(X_scaled)\n",
    "print(\"XGBoost Classifier\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Number of 1s (attacks): {np.sum(y_pred == 1)}\")\n",
    "print(f\"Number of 0s (normals): {np.sum(y_pred == 0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
